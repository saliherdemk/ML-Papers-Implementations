{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "639cc48e-3f0b-4c10-87e1-4ae0c6e58fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "f = open(\"./TinyShakespeare/input.txt\")\n",
    "text = f.read()\n",
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89369042-5ef6-4172-8f23-d50f57189ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95ba4065-0197-4785-a756-d608575ce6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_idx = {ch:i for i, ch in enumerate(chars)}\n",
    "idx_to_char = {i:ch for i, ch in enumerate(chars)}\n",
    "\n",
    "def encode(text):\n",
    "    return [char_to_idx[ch] for ch in text]\n",
    "\n",
    "def decode(idx):\n",
    "    return [idx_to_char[i] for i in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc8930c4-e038-4c02-b55e-34f74cdc05cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1115394])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "092a8d5e-824d-42e8-9438-6cec7ec9602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "test_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d67141f9-7086-40c3-8a16-18c44537f315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18]) tensor(47)\n",
      "tensor([18, 47]) tensor(56)\n",
      "tensor([18, 47, 56]) tensor(57)\n",
      "tensor([18, 47, 56, 57]) tensor(58)\n",
      "tensor([18, 47, 56, 57, 58]) tensor(1)\n",
      "tensor([18, 47, 56, 57, 58,  1]) tensor(15)\n",
      "tensor([18, 47, 56, 57, 58,  1, 15]) tensor(47)\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47]) tensor(58)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_length = 8\n",
    "x = train_data[:sequence_length]\n",
    "y = train_data[1:sequence_length + 1]\n",
    "for t in range(sequence_length):\n",
    "    context = x[:t + 1]\n",
    "    target = y[t]\n",
    "    print(context, target)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fb55732-7703-4444-9d17-1f9a8899c306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "\n",
    "class ContextTargetDataset(Dataset):\n",
    "    def __init__(self, data, window_size):\n",
    "        self.data = data\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.window_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_idx = random.randint(0, len(self.data) - self.window_size - 1)\n",
    "        x = self.data[start_idx : start_idx + self.window_size]\n",
    "        y = self.data[start_idx + 1 : start_idx + self.window_size + 1]\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "    def collate_fn(batch):\n",
    "        xs, ys = zip(*batch)\n",
    "        return torch.stack(xs), torch.stack(ys)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65f3ab6e-c410-411d-af56-a2439f780e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  tensor([[53,  1, 58, 46, 43,  1, 58, 47],\n",
      "        [47, 57,  1, 50, 47, 60, 43, 57]])\n",
      "Y:  tensor([[ 1, 58, 46, 43,  1, 58, 47, 51],\n",
      "        [57,  1, 50, 47, 60, 43, 57,  1]])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dataset = ContextTargetDataset(train_data, window_size=8)\n",
    "train_loader = DataLoader(train_dataset, batch_size=2)\n",
    "\n",
    "test_dataset = ContextTargetDataset(test_data, window_size=8)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2)\n",
    "for batch_x, batch_y in test_loader:\n",
    "    print(\"X: \", batch_x)\n",
    "    print(\"Y: \", batch_y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ef1f550-9e5f-4497-9522-259f3613b380",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 32\n",
    "hidden_size = 64\n",
    "output_size = vocab_size\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc143ed-6268-4b6e-bbec-5d20c88b0ee8",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ddf217f-f741-4b39-9f74-c55f748f99bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.W_xh = nn.Parameter(torch.randn(hidden_size, embed_dim))\n",
    "        self.W_hh = nn.Parameter(torch.randn(hidden_size, hidden_size))\n",
    "        self.b_h = nn.Parameter(torch.zeros(hidden_size))\n",
    "        \n",
    "        self.W_hy = nn.Parameter(torch.randn(output_size, hidden_size))\n",
    "        self.b_y = nn.Parameter(torch.zeros(output_size))\n",
    "\n",
    "    def step(self, x_t, h_t):\n",
    "        h_t = torch.tanh(x_t @ self.W_xh.T + h_t @ self.W_hh.T + self.b_h)\n",
    "        y_t = h_t @ self.W_hy.T + self.b_y\n",
    "        return y_t, h_t\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.shape\n",
    "        x_embed = self.embedding(x)\n",
    "        h_t = torch.zeros(batch_size, self.hidden_size).to(device)\n",
    "\n",
    "        outputs = []\n",
    "        \n",
    "        for t in range(seq_len):\n",
    "            x_t = x_embed[:,t, :]\n",
    "\n",
    "            y_t, h_t = self.step(x_t, h_t)\n",
    "            outputs.append(y_t)\n",
    "            \n",
    "        outputs = torch.stack(outputs, dim=1)\n",
    "        return outputs\n",
    "\n",
    "    def generate(self, start_token, sample_size = 100):\n",
    "        self.eval()\n",
    "    \n",
    "        input_seq = torch.tensor([[char_to_idx[start_token]]], dtype=torch.long).to(device)\n",
    "        generated = [start_token]\n",
    "        \n",
    "        h_t = torch.zeros(1, model.hidden_size).to(device)\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for _ in range(sample_size):\n",
    "                x_embed = model.embedding(input_seq[:, -1])\n",
    "                y_t, h_t = self.step(x_embed, h_t)\n",
    "                \n",
    "                probs = torch.softmax(y_t, dim=-1)\n",
    "                next_token_id = torch.multinomial(probs, num_samples=1).item()\n",
    "                \n",
    "                next_token = idx_to_char[next_token_id]\n",
    "                generated.append(next_token)\n",
    "                \n",
    "                input_seq = torch.cat([input_seq, torch.tensor([[next_token_id]]).to(device)], dim=1)\n",
    "        \n",
    "        return ''.join(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d337eae1-c067-4e6f-af02-7179d4f802b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(vocab_size, embed_dim, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b761ed0a-be0c-4a6b-a354-0406dd47eb1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a5d78b8e1c499d8396d2f79416d9c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/31371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebcfd1444ad6490e8189eaa2463d73a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5:   0%|          | 0/31371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b86c84aaeb5b4f968d6d4d0cb0ae0613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5:   0%|          | 0/31371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb5aa888d95c463d8683ed84b2f0b675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5:   0%|          | 0/31371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d010f3475fe4499a8a89dc1f14c2f1a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5:   0%|          | 0/31371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 5 epochs, loss: 1.8875628292326878\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "train_loader = DataLoader(train_dataset, batch_size=32)\n",
    "epochs = 5\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
    "\n",
    "    for  i, (batch_x, batch_y) in enumerate(loop, 1):\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs.view(-1, vocab_size), batch_y.view(-1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / i\n",
    "        loop.set_postfix(batch_loss=loss.item(), avg_loss=avg_loss)\n",
    "print(f\"After {epochs} epochs, loss: {avg_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c9207205-23e8-4dc0-84ec-cca32b0d4b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lof to sanavour the shall fathersigh the cearth, your you hore of do treball, bid ther.\n",
      "\n",
      "LEONTHARD SICINIUS:\n",
      "Ray\n",
      "To good Sonot yoest that to blenspest pittle hear acty.\n",
      "But; the come,\n",
      "Puto\n",
      "Lord pead, and.\n",
      "Proudin;\n",
      "Why frised! Pettell all go thal with is lord?\n",
      "\n",
      "VOLUOMEIO:\n",
      "Nall Rave so, witd the to tooy sovather,'s out, go; their thim. no, fremeetherd.\n",
      "\n",
      "AANUS:\n",
      "Where me upon it fripe,\n",
      "Ward?\n",
      "\n",
      "ey!\n",
      "\n",
      "ISABELLA:\n",
      "By; 'rd's tom louthrul all, and,\n",
      "And not to\n",
      "RICLA:\n",
      "I thope Pale\n",
      "Your lastispar I sonst che he\n"
     ]
    }
   ],
   "source": [
    "print(model.generate(start_token='\\n', sample_size = 500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69b319e-c0fe-4d82-a7dc-cbfc0bf3ddfb",
   "metadata": {},
   "source": [
    "# Torch RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d49f1a63-4f93-4407-8fb2-b5bc511fa672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class TorchRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_size, output_size):\n",
    "        super(TorchRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.rnn = nn.RNN(embed_dim, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_embed = self.embedding(x)\n",
    "        out, _ = self.rnn(x_embed)\n",
    "        logits = self.fc(out)\n",
    "        return logits\n",
    "\n",
    "    def generate(self, start_token, sample_size = 100):\n",
    "        self.eval()\n",
    "        generated = [start_token]\n",
    "        \n",
    "        input_token = torch.tensor([[char_to_idx.get(start_token)]]).to(device)\n",
    "        h_t = None\n",
    "        with torch.no_grad():\n",
    "            for _ in range(sample_size):\n",
    "                logits = self.forward(input_token)\n",
    "                logits = logits[:, -1, :] \n",
    "                probs = torch.softmax(logits, dim=-1)\n",
    "                \n",
    "                next_token_id = torch.multinomial(probs, num_samples=1).item()\n",
    "                next_token = idx_to_char[next_token_id]\n",
    "                generated.append(next_token)\n",
    "                \n",
    "                input_token = torch.tensor([[next_token_id]]).to(device)\n",
    "    \n",
    "        return ''.join(generated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "068215d3-e2b1-4a91-abf4-8ebfb34a1cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model = TorchRNN(vocab_size, embed_dim, hidden_size, output_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54910c19-ab00-47c4-bb9e-e167f959f76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c41025e540450685be1c16ed6e67e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/31371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47880568a5ef4c61b07237f07dba5a65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5:   0%|          | 0/31371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f26f3cb1dd384698a370c90ee8583134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5:   0%|          | 0/31371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "261ec7d9b1ae4049b604c4fa229d97db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5:   0%|          | 0/31371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c3948442bca42a58467bb58a8ff522a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5:   0%|          | 0/31371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 5 epochs, loss: 1.8620590770374938\n"
     ]
    }
   ],
   "source": [
    "torch_optimizer = torch.optim.AdamW(torch_model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(5):\n",
    "    torch_model.train()\n",
    "    total_loss = 0\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/5\", leave=False)\n",
    "\n",
    "    for i, (batch_x, batch_y) in enumerate(loop, 1):\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        outputs = torch_model(batch_x)\n",
    "\n",
    "        loss = criterion(outputs.view(-1, vocab_size), batch_y.view(-1))\n",
    "\n",
    "        torch_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        avg_loss = total_loss / i\n",
    "        loop.set_postfix(batch_loss=loss.item(), avg_loss=avg_loss)\n",
    "\n",
    "print(f\"After {epochs} epochs, loss: {avg_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d99f1264-7d66-44f4-a3c0-36df8b2fa94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask onghean, s y ARKI:\n",
      "Wh silit\n",
      "HAn se ftusowen, I os poube lll sarwnonlly sor p,\n",
      "I g ar?\n",
      "thit t, lesthacemangull th hasenes linth itha wondioureanglatlld.\n",
      "SI arvin'd s se ORack, dedordis f sere pn matrsisearndid. ENTe halot s by, he ce an t senort ad.\n",
      "V: van I horet ig CUSThthen ivee y d, s incin akinon,\n",
      "PE:\n",
      "Thawallon.\n",
      "\n",
      "A we anghingr,\n",
      "Me\n",
      "\n",
      "Th thame t\n",
      "Sth n ng le thos withthisouth\n",
      "TOf inof allldorthis:\n",
      "Swbanghele onobeng whonothat oushfe tls:\n",
      "H:\n",
      "\n",
      "\n",
      "D:\n",
      "T:\n",
      "F k wod th mar atay st buse ot ceeldootyod \n"
     ]
    }
   ],
   "source": [
    "output = torch_model.generate(start_token = '\\n', sample_size = 500)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1a335c-306b-42d2-8b22-8c77603c2e9c",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "888399e1-4401-4f96-8cbc-f77ad5d14694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_size, output_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.W_ii = nn.Parameter(torch.randn(hidden_size, embed_dim))\n",
    "        self.W_hi = nn.Parameter(torch.randn(hidden_size, hidden_size))\n",
    "\n",
    "        self.W_if = nn.Parameter(torch.randn(hidden_size, embed_dim))\n",
    "        self.W_hf = nn.Parameter(torch.randn(hidden_size, hidden_size))\n",
    "\n",
    "        self.W_ig = nn.Parameter(torch.randn(hidden_size, embed_dim))\n",
    "        self.W_hg = nn.Parameter(torch.randn(hidden_size, hidden_size))\n",
    "\n",
    "        self.W_io = nn.Parameter(torch.randn(hidden_size, embed_dim))\n",
    "        self.W_ho = nn.Parameter(torch.randn(hidden_size, hidden_size))\n",
    "\n",
    "        self.b_ii = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.b_hi = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.b_if = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.b_hf = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.b_ig = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.b_hg = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.b_io = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.b_ho = nn.Parameter(torch.zeros(hidden_size))\n",
    "\n",
    "        self.fc_out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def step(self, x_t, h_t, c_t):\n",
    "        i_t = torch.sigmoid(x_t @ self.W_ii.T + self.b_ii + h_t @ self.W_hi.T + self.b_hi)\n",
    "        f_t = torch.sigmoid(x_t @ self.W_if.T + self.b_if + h_t @ self.W_hf.T + self.b_hf)\n",
    "        g_t = torch.tanh(x_t @ self.W_ig.T + self.b_ig + h_t @ self.W_hg.T + self.b_hg)\n",
    "        o_t = torch.sigmoid(x_t @ self.W_io.T + self.b_io + h_t @ self.W_ho.T + self.b_ho)\n",
    "\n",
    "        c_t = f_t * c_t + i_t * g_t\n",
    "        h_t = o_t * torch.tanh(c_t)\n",
    "\n",
    "        return h_t, c_t\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.shape\n",
    "        x_embed = self.embedding(x)\n",
    "        h_t = torch.zeros(batch_size, self.hidden_size).to(device)\n",
    "        c_t = torch.zeros(batch_size, self.hidden_size).to(device)\n",
    "        \n",
    "        outputs = []\n",
    "        for t in range(seq_len):\n",
    "            x_t = x_embed[:,t, :]\n",
    "            h_t, c_t = self.step(x_t, h_t, c_t)\n",
    "            \n",
    "            outputs.append(h_t)\n",
    "            \n",
    "        outputs = torch.stack(outputs, dim=1)\n",
    "        outputs = self.fc_out(outputs)\n",
    "        return outputs\n",
    "\n",
    "    def generate(self, start_token, sample_size=100):\n",
    "        self.eval()\n",
    "        input_seq = torch.tensor([[char_to_idx[start_token]]], dtype=torch.long).to(device)\n",
    "        generated = [start_token]\n",
    "\n",
    "        h_t = torch.zeros(1, self.hidden_size).to(device)\n",
    "        c_t = torch.zeros(1, self.hidden_size).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for _ in range(sample_size):\n",
    "                x_embed = self.embedding(input_seq[:, -1])\n",
    "                h_t, c_t = self.step(x_embed, h_t, c_t)\n",
    "                y_t = self.fc_out(h_t)\n",
    "                probs = torch.softmax(y_t, dim=-1)\n",
    "                next_token_id = torch.multinomial(probs, num_samples=1).item()\n",
    "                next_token = idx_to_char[next_token_id]\n",
    "                generated.append(next_token)\n",
    "\n",
    "                input_seq = torch.cat([input_seq, torch.tensor([[next_token_id]]).to(device)], dim=1)\n",
    "\n",
    "        return ''.join(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f84b47fc-46fe-4300-b9ad-d3ca5a3d7d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = LSTM(vocab_size, embed_dim, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "511e15e3-d0f3-4d05-bcc4-539dfa952d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de735b6c73224cff8d541a33b96b1ed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/31371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "525fa840948a49d7a73071f519e968ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5:   0%|          | 0/31371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47fc4637fea544348aaf9d1603323678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5:   0%|          | 0/31371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6afca8d7bee4bccacf568269f1e67a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5:   0%|          | 0/31371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4c3fdd536d493885d6a3db201cb458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5:   0%|          | 0/31371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 5 epochs, loss: 1.7623790918608435\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "train_loader = DataLoader(train_dataset, batch_size=32)\n",
    "epochs = 5\n",
    "optimizer = torch.optim.AdamW(lstm_model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "lstm_model.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    lstm_model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
    "\n",
    "    for  i, (batch_x, batch_y) in enumerate(loop, 1):\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        outputs = lstm_model(batch_x)\n",
    "        loss = criterion(outputs.view(-1, vocab_size), batch_y.view(-1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / i\n",
    "        loop.set_postfix(batch_loss=loss.item(), avg_loss=avg_loss)\n",
    "print(f\"After {epochs} epochs, loss: {avg_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "380ff0ed-cb1d-49ce-ad98-915f98be24a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "How both:\n",
      "Of him.\n",
      "\n",
      "ROMEO:\n",
      "Where have, take homb, with pricklifi'nse gencal hence-damed hatpementle bect base though dears, what faclest alowse! for Michongue\n",
      "To plancommy power, more come, you rict it true my right death,\n",
      "Nestrange, fledsul, his trithalle; as unto Nith his breather foll.\n",
      "\n",
      "JULIET:\n",
      "As and I shting, percreasonsic\n",
      "Whom my wirempher goward, alt go:\n",
      "I am thou have is you are nett takeshesion,\n",
      "But barms, what form to are suffelt am Hermis the art the tere must:\n",
      "Ime, to night is thou ma\n"
     ]
    }
   ],
   "source": [
    "output = lstm_model.generate(\"\\n\", 500)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729d3f1e-9ce4-4b2a-8b2a-a6912acb293e",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "948f956e-1211-46b8-bb40-7e56bdd91f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class GRU(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_size , output_size):\n",
    "        super(GRU, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.W_ir = nn.Parameter(torch.randn(hidden_size, embed_dim))\n",
    "        self.W_hr = nn.Parameter(torch.randn(hidden_size, hidden_size))\n",
    "        \n",
    "        self.W_iz = nn.Parameter(torch.randn(hidden_size, embed_dim))\n",
    "        self.W_hz = nn.Parameter(torch.randn(hidden_size, hidden_size))\n",
    "        \n",
    "        self.W_in = nn.Parameter(torch.randn(hidden_size, embed_dim))\n",
    "        self.W_hn = nn.Parameter(torch.randn(hidden_size, hidden_size))\n",
    "\n",
    "        self.b_ir = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.b_hr = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.b_iz = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.b_hz = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.b_in = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.b_hn = nn.Parameter(torch.zeros(hidden_size))\n",
    "\n",
    "        self.fc_out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "\n",
    "    def step(self, x_t, h_t):\n",
    "        r_t = torch.sigmoid(x_t @ self.W_ir.T + self.b_ir + h_t @ self.W_hr.T + self.b_hr)\n",
    "        z_t = torch.sigmoid(x_t @ self.W_iz.T + self.b_iz + h_t @ self.W_hz.T + self.b_hz)\n",
    "        n_t = torch.tanh(x_t @ self.W_in.T + self.b_in + r_t * (h_t @ self.W_hn.T + self.b_hn))\n",
    "        h_t = (1 - z_t) * n_t + z_t * h_t\n",
    "\n",
    "        return h_t\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.shape\n",
    "        x_embed = self.embedding(x)\n",
    "        h_t = torch.zeros(batch_size, self.hidden_size).to(device)\n",
    "        \n",
    "        outputs = []\n",
    "        for t in range(seq_len):\n",
    "            x_t = x_embed[:,t, :]\n",
    "            h_t = self.step(x_t, h_t)\n",
    "            \n",
    "            outputs.append(h_t)\n",
    "            \n",
    "        outputs = torch.stack(outputs, dim=1)\n",
    "        outputs = self.fc_out(outputs)\n",
    "        return outputs\n",
    "\n",
    "    def generate(self, start_token, sample_size=100):\n",
    "        self.eval()\n",
    "        input_seq = torch.tensor([[char_to_idx[start_token]]], dtype=torch.long).to(device)\n",
    "        generated = [start_token]\n",
    "\n",
    "        h_t = torch.zeros(1, self.hidden_size).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for _ in range(sample_size):\n",
    "                x_embed = self.embedding(input_seq[:, -1])\n",
    "                h_t = self.step(x_embed, h_t)\n",
    "                y_t = self.fc_out(h_t)\n",
    "                probs = torch.softmax(y_t, dim=-1)\n",
    "                next_token_id = torch.multinomial(probs, num_samples=1).item()\n",
    "                next_token = idx_to_char[next_token_id]\n",
    "                generated.append(next_token)\n",
    "\n",
    "                input_seq = torch.cat([input_seq, torch.tensor([[next_token_id]]).to(device)], dim=1)\n",
    "\n",
    "        return ''.join(generated)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebfcbef0-f750-4e49-8729-5d7e80b01c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model = GRU(vocab_size, embed_dim, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd7a75f2-ddc5-4de7-a23c-110d5d33cbbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "340a2beacd424b9791797b9d62d73180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/31371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5944a8187b34218850af36744b6451b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5:   0%|          | 0/31371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ce6f0479d9f4301b605443412e1fd62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5:   0%|          | 0/31371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb895f5ba5304f1eae6709978c3817ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5:   0%|          | 0/31371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a157258a910840ada07adccabdc7d577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5:   0%|          | 0/31371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 5 epochs, loss: 1.800975421192367\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "train_loader = DataLoader(train_dataset, batch_size=32)\n",
    "epochs = 5\n",
    "optimizer = torch.optim.AdamW(gru_model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "gru_model.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    gru_model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
    "\n",
    "    for  i, (batch_x, batch_y) in enumerate(loop, 1):\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        outputs = gru_model(batch_x)\n",
    "        loss = criterion(outputs.view(-1, vocab_size), batch_y.view(-1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / i\n",
    "        loop.set_postfix(batch_loss=loss.item(), avg_loss=avg_loss)\n",
    "\n",
    "print(f\"After {epochs} epochs, loss: {avg_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8272c025-3d68-4926-b66f-0d23e1d265c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "If I was and Angelf and the RICAY:\n",
      "Iwict\n",
      "Ot I we best me indordman know I have he\n",
      "ch'd onined greadom this gracioure on thesels for and ambed of.\n",
      "\n",
      "CKINCELIZE:\n",
      "Go; seen\n",
      "By dividing time him.\n",
      "My.\n",
      "Teepantave; not\n",
      "Ochrays\n",
      "He more you, my from son-boy.\n",
      "\n",
      "First Buick and!\n",
      "What be studon to lie.\n",
      "\n",
      "CLIFK:\n",
      "Loicle! see acle, from himselfes.\n",
      "\n",
      "ESCALUS: brotten,\n",
      "Ingar?\n",
      "\n",
      "POMPEY:\n",
      "With minstill'd shall noth see:\n",
      "Noth to and thus broads, wifl, I foul love for not wells,' did chosely got:\n",
      "\n",
      "Sevoling buse her betimel\n"
     ]
    }
   ],
   "source": [
    "output = gru_model.generate(\"\\n\", 500)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e8f619-6ef9-4eb5-b26f-ede1568254d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
