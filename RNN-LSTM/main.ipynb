{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "639cc48e-3f0b-4c10-87e1-4ae0c6e58fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "f = open(\"./TinyShakespeare/input.txt\")\n",
    "text = f.read()\n",
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89369042-5ef6-4172-8f23-d50f57189ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95ba4065-0197-4785-a756-d608575ce6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_idx = {ch:i for i, ch in enumerate(chars)}\n",
    "idx_to_char = {i:ch for i, ch in enumerate(chars)}\n",
    "\n",
    "def encode(text):\n",
    "    return [char_to_idx[ch] for ch in text]\n",
    "\n",
    "def decode(idx):\n",
    "    return [idx_to_char[i] for i in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc8930c4-e038-4c02-b55e-34f74cdc05cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1115394])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "092a8d5e-824d-42e8-9438-6cec7ec9602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "test_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d67141f9-7086-40c3-8a16-18c44537f315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18]) tensor(47)\n",
      "tensor([18, 47]) tensor(56)\n",
      "tensor([18, 47, 56]) tensor(57)\n",
      "tensor([18, 47, 56, 57]) tensor(58)\n",
      "tensor([18, 47, 56, 57, 58]) tensor(1)\n",
      "tensor([18, 47, 56, 57, 58,  1]) tensor(15)\n",
      "tensor([18, 47, 56, 57, 58,  1, 15]) tensor(47)\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47]) tensor(58)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_length = 8\n",
    "x = train_data[:sequence_length]\n",
    "y = train_data[1:sequence_length + 1]\n",
    "for t in range(sequence_length):\n",
    "    context = x[:t + 1]\n",
    "    target = y[t]\n",
    "    print(context, target)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fb55732-7703-4444-9d17-1f9a8899c306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "\n",
    "class ContextTargetDataset(Dataset):\n",
    "    def __init__(self, data, window_size):\n",
    "        self.data = data\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.window_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_idx = random.randint(0, len(self.data) - self.window_size - 1)\n",
    "        x = self.data[start_idx : start_idx + self.window_size]\n",
    "        y = self.data[start_idx + 1 : start_idx + self.window_size + 1]\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "    def collate_fn(batch):\n",
    "        xs, ys = zip(*batch)\n",
    "        return torch.stack(xs), torch.stack(ys)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65f3ab6e-c410-411d-af56-a2439f780e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  tensor([[61, 47, 50, 50,  1, 40, 43,  1],\n",
      "        [59, 58,  1, 58, 46, 56, 43, 43]])\n",
      "Y:  tensor([[47, 50, 50,  1, 40, 43,  1, 58],\n",
      "        [58,  1, 58, 46, 56, 43, 43,  1]])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dataset = ContextTargetDataset(train_data, window_size=8)\n",
    "train_loader = DataLoader(train_dataset, batch_size=2)\n",
    "\n",
    "test_dataset = ContextTargetDataset(test_data, window_size=8)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2)\n",
    "for batch_x, batch_y in test_loader:\n",
    "    print(\"X: \", batch_x)\n",
    "    print(\"Y: \", batch_y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ef1f550-9e5f-4497-9522-259f3613b380",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 32\n",
    "hidden_size = 64\n",
    "output_size = vocab_size\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc143ed-6268-4b6e-bbec-5d20c88b0ee8",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ddf217f-f741-4b39-9f74-c55f748f99bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.W_xh = nn.Parameter(torch.randn(hidden_size, embed_dim))\n",
    "        self.W_hh = nn.Parameter(torch.randn(hidden_size, hidden_size))\n",
    "        self.b_h = nn.Parameter(torch.zeros(hidden_size))\n",
    "        \n",
    "        self.W_hy = nn.Parameter(torch.randn(output_size, hidden_size))\n",
    "        self.b_y = nn.Parameter(torch.zeros(output_size))\n",
    "\n",
    "    def step(self, x_t, h_t):\n",
    "        h_t = torch.tanh(x_t @ self.W_xh.T + h_t @ self.W_hh.T + self.b_h)\n",
    "        y_t = h_t @ self.W_hy.T + self.b_y\n",
    "        return y_t, h_t\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.shape\n",
    "        x_embed = self.embedding(x)\n",
    "        h_t = torch.zeros(batch_size, self.hidden_size).to(device)\n",
    "\n",
    "        outputs = []\n",
    "        \n",
    "        for t in range(seq_len):\n",
    "            x_t = x_embed[:,t, :]\n",
    "\n",
    "            y_t, h_t = self.step(x_t, h_t)\n",
    "            outputs.append(y_t)\n",
    "            \n",
    "        outputs = torch.stack(outputs, dim=1)\n",
    "        return outputs\n",
    "\n",
    "    def generate(self, start_token, sample_size = 100):\n",
    "        self.eval()\n",
    "    \n",
    "        input_seq = torch.tensor([[char_to_idx[start_token]]], dtype=torch.long).to(device)\n",
    "        generated = [start_token]\n",
    "        \n",
    "        h_t = torch.zeros(1, model.hidden_size).to(device)\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for _ in range(sample_size):\n",
    "                x_embed = model.embedding(input_seq[:, -1])\n",
    "                y_t, h_t = self.step(x_embed, h_t)\n",
    "                \n",
    "                probs = torch.softmax(y_t, dim=-1)\n",
    "                next_token_id = torch.multinomial(probs, num_samples=1).item()\n",
    "                \n",
    "                next_token = idx_to_char[next_token_id]\n",
    "                generated.append(next_token)\n",
    "                \n",
    "                input_seq = torch.cat([input_seq, torch.tensor([[next_token_id]]).to(device)], dim=1)\n",
    "        \n",
    "        return ''.join(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d337eae1-c067-4e6f-af02-7179d4f802b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(vocab_size, embed_dim, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b761ed0a-be0c-4a6b-a354-0406dd47eb1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "466265b7772342c5b44dba1201d051d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/31371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "354db7ab251f4831b699a5ddd023b877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5:   0%|          | 0/31371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a5b41e210e64f5a9de54a777d98939f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5:   0%|          | 0/31371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df57c47988c497f8f941ea23cc31964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5:   0%|          | 0/31371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e79e8c2ef56b457ca55318a0feb9ee8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5:   0%|          | 0/31371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "train_loader = DataLoader(train_dataset, batch_size=32)\n",
    "epochs = 5\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "    for  i, (batch_x, batch_y) in enumerate(loop, 1):\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs.view(-1, vocab_size), batch_y.view(-1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / i\n",
    "        loop.set_postfix(batch_loss=loss.item(), avg_loss=avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9207205-23e8-4dc0-84ec-cca32b0d4b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The led so fdition, guither.' I save.\n",
      "O, a more in it griter, tir, thy gatenty houset\n",
      "Bramen purgel I will you gore ats in hork,\n",
      "Thou fist, proo if!\n",
      "What on they -\n",
      "\n",
      "You foltor on to the folt pringhall's poonery\n",
      "selfollo, the prace,\n",
      "To you tie thou should gry a loak'd we it whfances do boman's nation\n",
      "Resing in be my gracuetes-liveich rik too cum mailt.\n",
      "\n",
      "TIO:\n",
      "He-losectirs the Mowisback it jo: thou!\n",
      "And stare no muct our papear my made, poor their Marcan mutore bUtreet.\n",
      "\n",
      "Sear.\n",
      "\n",
      "BRUTUS:\n",
      "As we shall \n"
     ]
    }
   ],
   "source": [
    "print(model.generate(start_token='\\n', sample_size = 500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69b319e-c0fe-4d82-a7dc-cbfc0bf3ddfb",
   "metadata": {},
   "source": [
    "# Torch RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d49f1a63-4f93-4407-8fb2-b5bc511fa672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class TorchRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_size, output_size):\n",
    "        super(TorchRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.rnn = nn.RNN(embed_dim, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_embed = self.embedding(x)\n",
    "        out, _ = self.rnn(x_embed)\n",
    "        logits = self.fc(out)\n",
    "        return logits\n",
    "\n",
    "    def generate(self, start_token, sample_size = 100):\n",
    "        self.eval()\n",
    "        generated = [start_token]\n",
    "        \n",
    "        input_token = torch.tensor([[char_to_idx.get(start_token)]]).to(device)\n",
    "        h_t = None\n",
    "        with torch.no_grad():\n",
    "            for _ in range(sample_size):\n",
    "                logits = self.forward(input_token)\n",
    "                logits = logits[:, -1, :] \n",
    "                probs = torch.softmax(logits, dim=-1)\n",
    "                \n",
    "                next_token_id = torch.multinomial(probs, num_samples=1).item()\n",
    "                next_token = idx_to_char[next_token_id]\n",
    "                generated.append(next_token)\n",
    "                \n",
    "                input_token = torch.tensor([[next_token_id]]).to(device)\n",
    "    \n",
    "        return ''.join(generated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "068215d3-e2b1-4a91-abf4-8ebfb34a1cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model = TorchRNN(vocab_size, embed_dim, hidden_size, output_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54910c19-ab00-47c4-bb9e-e167f959f76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46c52de931c24e358e69d9e59a95dd23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/31371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a6308776134d3aba4c89266003c0ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5:   0%|          | 0/31371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "636ec0d28c8c485ab1b9b701e2fc712a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5:   0%|          | 0/31371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03b04d748b044abd91bc41d0adc4974e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5:   0%|          | 0/31371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc0afdecfebd481191ab6cd2ea6f150d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5:   0%|          | 0/31371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch_optimizer = torch.optim.AdamW(torch_model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(5):\n",
    "    torch_model.train()\n",
    "    total_loss = 0\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/5\")\n",
    "\n",
    "    for i, (batch_x, batch_y) in enumerate(loop, 1):\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        outputs = torch_model(batch_x)\n",
    "\n",
    "        loss = criterion(outputs.view(-1, vocab_size), batch_y.view(-1))\n",
    "\n",
    "        torch_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        avg_loss = total_loss / i\n",
    "        loop.set_postfix(batch_loss=loss.item(), avg_loss=avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d99f1264-7d66-44f4-a3c0-36df8b2fa94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thoury?\n",
      "Theageser the wed ameayoorrd wo'sthe oth wherepe esthothand t. olt tr yoppplames l, isea ik thig sthepond:\n",
      "Ar gioug ugeear t prbarel,-w tht thereas ishararouthe rd oou at fe paindr y bey ghoourin'lor llfint to,\n",
      "\n",
      "MI t l l\n",
      "HAce peme blswout loothe alt he shir Sond y\n",
      "\n",
      "LAUSent. bol.\n",
      "\n",
      "COPERIfe t\n",
      "GLAMyome lfouererorowinsthe.\n",
      "GUSe hasthend ighally ot mowo, woun ourd te wid ong:\n",
      "Thit s sakeds hot mer s l lk Gofthmorifistlleanols h bed lere domy prr!\n",
      "\n",
      "Torrorway iend plo thin.\n",
      "Bucemu.\n",
      "Wieeall heth\n"
     ]
    }
   ],
   "source": [
    "output = torch_model.generate(start_token = '\\n', sample_size = 500)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1a335c-306b-42d2-8b22-8c77603c2e9c",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "888399e1-4401-4f96-8cbc-f77ad5d14694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_size, output_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.W_ii = nn.Parameter(torch.randn(hidden_size, embed_dim))\n",
    "        self.W_hi = nn.Parameter(torch.randn(hidden_size, hidden_size))\n",
    "\n",
    "        self.W_if = nn.Parameter(torch.randn(hidden_size, embed_dim))\n",
    "        self.W_hf = nn.Parameter(torch.randn(hidden_size, hidden_size))\n",
    "\n",
    "        self.W_ig = nn.Parameter(torch.randn(hidden_size, embed_dim))\n",
    "        self.W_hg = nn.Parameter(torch.randn(hidden_size, hidden_size))\n",
    "\n",
    "        self.W_io = nn.Parameter(torch.randn(hidden_size, embed_dim))\n",
    "        self.W_ho = nn.Parameter(torch.randn(hidden_size, hidden_size))\n",
    "\n",
    "        self.b_ii = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.b_hi = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.b_if = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.b_hf = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.b_ig = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.b_hg = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.b_io = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.b_ho = nn.Parameter(torch.zeros(hidden_size))\n",
    "\n",
    "        self.fc_out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def step(self, x_t, h_t, c_t):\n",
    "        i_t = torch.sigmoid(x_t @ self.W_ii.T + self.b_ii + h_t @ self.W_hi.T + self.b_hi)\n",
    "        f_t = torch.sigmoid(x_t @ self.W_if.T + self.b_if + h_t @ self.W_hf.T + self.b_hf)\n",
    "        g_t = torch.tanh(x_t @ self.W_ig.T + self.b_ig + h_t @ self.W_hg.T + self.b_hg)\n",
    "        o_t = torch.sigmoid(x_t @ self.W_io.T + self.b_io + h_t @ self.W_ho.T + self.b_ho)\n",
    "\n",
    "        c_t = f_t * c_t + i_t * g_t\n",
    "        h_t = o_t * torch.tanh(c_t)\n",
    "\n",
    "        return h_t, c_t\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.shape\n",
    "        x_embed = self.embedding(x)\n",
    "        h_t = torch.zeros(batch_size, self.hidden_size).to(device)\n",
    "        c_t = torch.zeros(batch_size, self.hidden_size).to(device)\n",
    "        \n",
    "        outputs = []\n",
    "        for t in range(seq_len):\n",
    "            x_t = x_embed[:,t, :]\n",
    "            h_t, c_t = self.step(x_t, h_t, c_t)\n",
    "            \n",
    "            outputs.append(h_t)\n",
    "            \n",
    "        outputs = torch.stack(outputs, dim=1)\n",
    "        outputs = self.fc_out(outputs)\n",
    "        return outputs\n",
    "\n",
    "    def generate(self, start_token, sample_size=100):\n",
    "        self.eval()\n",
    "        input_seq = torch.tensor([[char_to_idx[start_token]]], dtype=torch.long).to(device)\n",
    "        generated = [start_token]\n",
    "\n",
    "        h_t = torch.zeros(1, self.hidden_size).to(device)\n",
    "        c_t = torch.zeros(1, self.hidden_size).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for _ in range(sample_size):\n",
    "                x_embed = self.embedding(input_seq[:, -1])\n",
    "                h_t, c_t = self.step(x_embed, h_t, c_t)\n",
    "                y_t = self.fc_out(h_t)\n",
    "                probs = torch.softmax(y_t, dim=-1)\n",
    "                next_token_id = torch.multinomial(probs, num_samples=1).item()\n",
    "                next_token = idx_to_char[next_token_id]\n",
    "                generated.append(next_token)\n",
    "\n",
    "                input_seq = torch.cat([input_seq, torch.tensor([[next_token_id]]).to(device)], dim=1)\n",
    "\n",
    "        return ''.join(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f84b47fc-46fe-4300-b9ad-d3ca5a3d7d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = LSTM(vocab_size, embed_dim, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "511e15e3-d0f3-4d05-bcc4-539dfa952d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8b32a2ad05044f2a06755f0be520c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/31371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7109f12a36f24febba837e09dd87447d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5:   0%|          | 0/31371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95bd1b780ae247059b8620b8f4fe3752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5:   0%|          | 0/31371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d51f97c5af7e4a6da67c7e3112cf6a5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5:   0%|          | 0/31371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23f3f15ac9f94a6e85290cf773004cf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5:   0%|          | 0/31371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "train_loader = DataLoader(train_dataset, batch_size=32)\n",
    "epochs = 5\n",
    "optimizer = torch.optim.AdamW(lstm_model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "lstm_model.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    lstm_model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "    for  i, (batch_x, batch_y) in enumerate(loop, 1):\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        outputs = lstm_model(batch_x)\n",
    "        loss = criterion(outputs.view(-1, vocab_size), batch_y.view(-1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / i\n",
    "        loop.set_postfix(batch_loss=loss.item(), avg_loss=avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "380ff0ed-cb1d-49ce-ad98-915f98be24a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No, pins, his dead?\n",
      "\n",
      "PERIVA:\n",
      "So shalt run is full the come to disnorn sorry. Come,\n",
      "For no bardon thou'resited, where the very\n",
      "Tough demiest o', and that Rebet, me now woman granks at you fraizens.\n",
      "NBEONTIFF YORK:\n",
      "I come\n",
      "'Tis confest rever me my grach ourou a patch\n",
      "Forself it refer her his sine!\n",
      "I truly here I,\n",
      "And as to the of it habt of anse not only.\n",
      "\n",
      "LEONTES:\n",
      "On I'll slails: theraminess ob'd frame such live sworn bowent:\n",
      "I save to hand, Pace, of spire etturs:\n",
      "Granly\n",
      "givn to in old may hence a\n"
     ]
    }
   ],
   "source": [
    "output = lstm_model.generate(\"\\n\", 500)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09964f74-e889-4b9a-8a1f-0e5fdf8459ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
