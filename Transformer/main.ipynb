{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67aeba07-8e1f-4583-a53f-c68e5fff047b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_random_dates(n=10000):\n",
    "    max_days = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "    dataset = set()\n",
    "    months = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
    "\n",
    "    for _ in range(n):\n",
    "        y = random.randint(1000, 2025)\n",
    "        m = random.randint(1, 12)\n",
    "\n",
    "        if (y % 4 == 0 and y % 100 != 0) or (y % 400 == 0):\n",
    "            max_days[1] = 29\n",
    "        else:\n",
    "            max_days[1] = 28\n",
    "\n",
    "        d = random.randint(1, max_days[m - 1])\n",
    "        dataset.add((f\"{y:04d}-{m:02d}-{d:02d}\", f\"{months[m - 1]} {d}, {y}\"))\n",
    "\n",
    "    return list(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76680890-deb1-444d-82fe-0bd22f37890a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1026-09-15</td>\n",
       "      <td>September 15, 1026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1075-12-16</td>\n",
       "      <td>December 16, 1075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1685-04-12</td>\n",
       "      <td>April 12, 1685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1658-11-22</td>\n",
       "      <td>November 22, 1658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1681-01-01</td>\n",
       "      <td>January 1, 1681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9878</th>\n",
       "      <td>1029-11-19</td>\n",
       "      <td>November 19, 1029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9879</th>\n",
       "      <td>1567-08-11</td>\n",
       "      <td>August 11, 1567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9880</th>\n",
       "      <td>1299-04-15</td>\n",
       "      <td>April 15, 1299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9881</th>\n",
       "      <td>1272-04-30</td>\n",
       "      <td>April 30, 1272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9882</th>\n",
       "      <td>1272-03-06</td>\n",
       "      <td>March 6, 1272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9883 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               x                   y\n",
       "0     1026-09-15  September 15, 1026\n",
       "1     1075-12-16   December 16, 1075\n",
       "2     1685-04-12      April 12, 1685\n",
       "3     1658-11-22   November 22, 1658\n",
       "4     1681-01-01     January 1, 1681\n",
       "...          ...                 ...\n",
       "9878  1029-11-19   November 19, 1029\n",
       "9879  1567-08-11     August 11, 1567\n",
       "9880  1299-04-15      April 15, 1299\n",
       "9881  1272-04-30      April 30, 1272\n",
       "9882  1272-03-06       March 6, 1272\n",
       "\n",
       "[9883 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = generate_random_dates()\n",
    "df = pd.DataFrame(dataset, columns=[\"x\", \"y\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a70ac2e2-fe34-43b7-8d9f-33033b5155ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(18)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"y\"].apply(lambda r : len(r)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1b60dec-aee1-4416-aa01-8587b77a78f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self):\n",
    "        nums = [str(i) for i in range(32)]\n",
    "        uppers = [chr(i) for i in range(ord('A'), ord('Z') + 1)]\n",
    "        lowers = [chr(i) for i in range(ord('a'), ord('z') + 1)]\n",
    "        self.input_max = 10 + 2\n",
    "        self.output_max = 18 + 2\n",
    "        self.vocab = nums + uppers + lowers + [\"-\", \",\", \" \", \"<sos>\", \"<eos>\", \"<pad>\"]\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        self.tokens_to_ids = {str(self.vocab[i]): i for i in range(len(self.vocab))}\n",
    "        self.ids_to_tokens = {str(i): str(self.vocab[i]) for i in range(len(self.vocab))}\n",
    "\n",
    "    def encode(self, sample):\n",
    "        x, y = sample\n",
    "        x = [\"<sos>\"] + list(x) + [\"<eos>\"]\n",
    "        y = [\"<sos>\"] + list(y) + [\"<eos>\"]\n",
    "        while len(x) != self.input_max: x.append(\"<pad>\")\n",
    "        while len(y) != self.output_max: y.append(\"<pad>\")\n",
    "        res_x = [self.tokens_to_ids[i] for i in x]\n",
    "        res_y = [self.tokens_to_ids[i] for i in y]\n",
    "\n",
    "        return (res_x, res_y)\n",
    "\n",
    "    def decode(self, ids):\n",
    "        res = [self.ids_to_tokens[str(i)] for i in ids]\n",
    "        return \"\".join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3545a45-7c78-456b-bd24-3777b1580b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<sos>1026-09-15<eos>', '1026-09-15')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "a = dataset[0]\n",
    "encoded_x, encoded_y = tokenizer.encode(a)\n",
    "tokenizer.decode(encoded_x), a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67e542d8-86ad-469a-88db-853bf866d4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[87, 1, 0, 2, 6, 84, 0, 9, 84, 1, 5, 88]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1f87cd1-a978-4b10-afdf-1c36e1c0aba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class DateDataset(Dataset):\n",
    "    def __init__(self,data, tokenizer):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_encoded, y_encoded = self.tokenizer.encode(self.data[idx])\n",
    "        \n",
    "        x_tensor = torch.tensor(x_encoded, dtype=torch.long)\n",
    "        y_tensor = torch.tensor(y_encoded, dtype=torch.long)\n",
    "\n",
    "        return x_tensor, y_tensor\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8241cb4d-bbb4-4026-9022-aba128f4e1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[87,  1,  4,  3,  2, 84,  1,  2, 84,  1,  4, 88],\n",
      "        [87,  1,  7,  4,  9, 84,  0,  7, 84,  0,  6, 88],\n",
      "        [87,  1,  1,  2,  1, 84,  0,  5, 84,  1,  6, 88],\n",
      "        [87,  1,  7,  4,  8, 84,  0,  2, 84,  2,  9, 88],\n",
      "        [87,  1,  6,  7,  3, 84,  1,  1, 84,  1,  4, 88]])\n",
      "tensor([[87, 35, 62, 60, 62, 70, 59, 62, 75, 86,  1,  4, 85, 86,  1,  4,  3,  2,\n",
      "         88, 89],\n",
      "        [87, 41, 78, 69, 82, 86,  6, 85, 86,  1,  7,  4,  9, 88, 89, 89, 89, 89,\n",
      "         89, 89],\n",
      "        [87, 44, 58, 82, 86,  1,  6, 85, 86,  1,  1,  2,  1, 88, 89, 89, 89, 89,\n",
      "         89, 89],\n",
      "        [87, 37, 62, 59, 75, 78, 58, 75, 82, 86,  2,  9, 85, 86,  1,  7,  4,  8,\n",
      "         88, 89],\n",
      "        [87, 45, 72, 79, 62, 70, 59, 62, 75, 86,  1,  4, 85, 86,  1,  6,  7,  3,\n",
      "         88, 89]])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "date_dataset = DateDataset(dataset, tokenizer)\n",
    "dataloader = DataLoader(date_dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "for batch_idx, (x_batch, y_batch) in enumerate(dataloader):\n",
    "    print(x_batch)\n",
    "    print(y_batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4623a119-d819-48f5-82bc-b7df7a010d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "\n",
    "    def forward(self, token_ids):\n",
    "        return self.embedding(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3e4fabd-7e7a-4b58-b2cc-9a66dbaa198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self, embed_dim, max_len, n = 10000):\n",
    "        super().__init__()\n",
    "        self.n = n\n",
    "        pe = torch.zeros(max_len, embed_dim)\n",
    "        positions = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, embed_dim, 2).float() * (-math.log(self.n) / embed_dim))\n",
    "                \n",
    "        pe[:, 0::2] = torch.sin(positions * div_term)\n",
    "        pe[:, 1::2] = torch.cos(positions * div_term)\n",
    "        print(pe.shape)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len = x.size(1)\n",
    "        pe = self.pe[:seq_len, :]\n",
    "        pe = pe.unsqueeze(0)\n",
    "        pe = pe.expand(x.size(0), -1, -1)\n",
    "        return x + pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da373a07-8a19-4c70-b8d2-fdf22ca05680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 16])\n",
      "torch.Size([5, 12, 16])\n",
      "torch.Size([5, 12, 16])\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 16\n",
    "max_seq_len = 20\n",
    "token_embedding_layer = TokenEmbedding(tokenizer.vocab_size, embed_dim)\n",
    "positional_encoding_layer = PositionalEncoder(embed_dim, max_seq_len)\n",
    "\n",
    "for batch_idx, (x_batch, y_batch) in enumerate(dataloader):\n",
    "    token_vectors = token_embedding_layer(x_batch)\n",
    "    print(token_vectors.shape)\n",
    "    input_vectors = positional_encoding_layer(token_vectors)\n",
    "    print(input_vectors.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2998f329-e1e1-4f0a-828b-7608f7650067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eacb0e9-4c86-44a5-86bb-011a65426f04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d110d8ca-f796-4c86-a63f-6d51ad06f1e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
