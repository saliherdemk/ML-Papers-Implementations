{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67aeba07-8e1f-4583-a53f-c68e5fff047b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_random_dates(n=10000):\n",
    "    max_days = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "    dataset = set()\n",
    "    months = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
    "\n",
    "    for _ in range(n):\n",
    "        y = random.randint(1000, 2025)\n",
    "        m = random.randint(1, 12)\n",
    "\n",
    "        if (y % 4 == 0 and y % 100 != 0) or (y % 400 == 0):\n",
    "            max_days[1] = 29\n",
    "        else:\n",
    "            max_days[1] = 28\n",
    "\n",
    "        d = random.randint(1, max_days[m - 1])\n",
    "        dataset.add((f\"{y:04d}-{m:02d}-{d:02d}\", f\"{months[m - 1]} {d}, {y}\"))\n",
    "\n",
    "    return list(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76680890-deb1-444d-82fe-0bd22f37890a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1676-11-30</td>\n",
       "      <td>November 30, 1676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1162-02-03</td>\n",
       "      <td>February 3, 1162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1394-03-23</td>\n",
       "      <td>March 23, 1394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1616-07-06</td>\n",
       "      <td>July 6, 1616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1647-05-03</td>\n",
       "      <td>May 3, 1647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9849</th>\n",
       "      <td>1577-03-14</td>\n",
       "      <td>March 14, 1577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9850</th>\n",
       "      <td>1763-05-23</td>\n",
       "      <td>May 23, 1763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9851</th>\n",
       "      <td>1998-08-29</td>\n",
       "      <td>August 29, 1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9852</th>\n",
       "      <td>1087-10-21</td>\n",
       "      <td>October 21, 1087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9853</th>\n",
       "      <td>1951-01-06</td>\n",
       "      <td>January 6, 1951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9854 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               x                  y\n",
       "0     1676-11-30  November 30, 1676\n",
       "1     1162-02-03   February 3, 1162\n",
       "2     1394-03-23     March 23, 1394\n",
       "3     1616-07-06       July 6, 1616\n",
       "4     1647-05-03        May 3, 1647\n",
       "...          ...                ...\n",
       "9849  1577-03-14     March 14, 1577\n",
       "9850  1763-05-23       May 23, 1763\n",
       "9851  1998-08-29    August 29, 1998\n",
       "9852  1087-10-21   October 21, 1087\n",
       "9853  1951-01-06    January 6, 1951\n",
       "\n",
       "[9854 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = generate_random_dates()\n",
    "df = pd.DataFrame(dataset, columns=[\"x\", \"y\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a70ac2e2-fe34-43b7-8d9f-33033b5155ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(18)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"y\"].apply(lambda r : len(r)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1b60dec-aee1-4416-aa01-8587b77a78f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self):\n",
    "        nums = [str(i) for i in range(10)]\n",
    "        uppers = [chr(i) for i in range(ord('A'), ord('Z') + 1)]\n",
    "        lowers = [chr(i) for i in range(ord('a'), ord('z') + 1)]\n",
    "        self.input_max = 10 + 2\n",
    "        self.output_max = 18 + 2\n",
    "        self.vocab = nums + uppers + lowers + [\"-\", \",\", \" \", \"<sos>\", \"<eos>\", \"<pad>\"]\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        self.tokens_to_ids = {str(self.vocab[i]): i for i in range(len(self.vocab))}\n",
    "        self.ids_to_tokens = {str(i): str(self.vocab[i]) for i in range(len(self.vocab))}\n",
    "\n",
    "        self.pad_token_id = self.tokens_to_ids[\"<pad>\"]\n",
    "\n",
    "    def encode(self, sample):\n",
    "        x, y = sample\n",
    "        x = [\"<sos>\"] + list(x) + [\"<eos>\"]\n",
    "        y = [\"<sos>\"] + list(y) + [\"<eos>\"]\n",
    "        while len(x) != self.input_max: x.append(\"<pad>\")\n",
    "        while len(y) != self.output_max: y.append(\"<pad>\")\n",
    "        res_x = [self.tokens_to_ids[i] for i in x]\n",
    "        res_y = [self.tokens_to_ids[i] for i in y]\n",
    "\n",
    "        return (res_x, res_y)\n",
    "\n",
    "    def decode(self, ids):\n",
    "        res = [self.ids_to_tokens[str(i)] for i in ids]\n",
    "        return \"\".join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d3545a45-7c78-456b-bd24-3777b1580b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<sos>1676-11-30<eos>',\n",
       " '1676-11-30',\n",
       " [65, 1, 6, 7, 6, 62, 1, 1, 62, 3, 0, 66],\n",
       " '-----',\n",
       " '<sos>November 30, 1676<eos><pad>',\n",
       " 'November 30, 1676',\n",
       " [65, 23, 50, 57, 40, 48, 37, 40, 53, 64, 3, 0, 63, 64, 1, 6, 7, 6, 66, 67])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "a = dataset[0]\n",
    "encoded_x, encoded_y = tokenizer.encode(a)\n",
    "tokenizer.decode(encoded_x), a[0], encoded_x, \"-----\", tokenizer.decode(encoded_y), a[1], encoded_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67e542d8-86ad-469a-88db-853bf866d4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68,\n",
       " 61,\n",
       " ('1676-11-30', 'November 30, 1676'),\n",
       " [65, 1, 6, 7, 6, 62, 1, 1, 62, 3, 0, 66])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size,tokenizer.tokens_to_ids[\"z\"], a, encoded_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1f87cd1-a978-4b10-afdf-1c36e1c0aba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class DateDataset(Dataset):\n",
    "    def __init__(self,data, tokenizer):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_encoded, y_encoded = self.tokenizer.encode(self.data[idx])\n",
    "        \n",
    "        x_tensor = torch.tensor(x_encoded, dtype=torch.long)\n",
    "        y_tensor = torch.tensor(y_encoded, dtype=torch.long)\n",
    "\n",
    "        return x_tensor, y_tensor\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8241cb4d-bbb4-4026-9022-aba128f4e1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[65,  1,  8,  4,  9, 62,  0,  2, 62,  2,  0, 66],\n",
      "        [65,  1,  5,  8,  5, 62,  0,  2, 62,  0,  2, 66],\n",
      "        [65,  1,  8,  0,  7, 62,  0,  9, 62,  2,  2, 66],\n",
      "        [65,  1,  0,  9,  3, 62,  0,  9, 62,  0,  6, 66],\n",
      "        [65,  1,  3,  1,  9, 62,  0,  2, 62,  1,  2, 66]])\n",
      "tensor([[65, 15, 40, 37, 53, 56, 36, 53, 60, 64,  2,  0, 63, 64,  1,  8,  4,  9,\n",
      "         66, 67],\n",
      "        [65, 15, 40, 37, 53, 56, 36, 53, 60, 64,  2, 63, 64,  1,  5,  8,  5, 66,\n",
      "         67, 67],\n",
      "        [65, 28, 40, 51, 55, 40, 48, 37, 40, 53, 64,  2,  2, 63, 64,  1,  8,  0,\n",
      "          7, 66],\n",
      "        [65, 28, 40, 51, 55, 40, 48, 37, 40, 53, 64,  6, 63, 64,  1,  0,  9,  3,\n",
      "         66, 67],\n",
      "        [65, 15, 40, 37, 53, 56, 36, 53, 60, 64,  1,  2, 63, 64,  1,  3,  1,  9,\n",
      "         66, 67]])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "date_dataset = DateDataset(dataset, tokenizer)\n",
    "dataloader = DataLoader(date_dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "for batch_idx, (x_batch, y_batch) in enumerate(dataloader):\n",
    "    print(x_batch)\n",
    "    print(y_batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4623a119-d819-48f5-82bc-b7df7a010d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "\n",
    "    def forward(self, token_ids):\n",
    "        return self.embedding(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c3e4fabd-7e7a-4b58-b2cc-9a66dbaa198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self, embed_dim, max_len, n = 10000):\n",
    "        super().__init__()\n",
    "        self.n = n\n",
    "        pe = torch.zeros(max_len, embed_dim)\n",
    "        positions = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, embed_dim, 2).float() * (-math.log(self.n) / embed_dim))\n",
    "                \n",
    "        pe[:, 0::2] = torch.sin(positions * div_term)\n",
    "        pe[:, 1::2] = torch.cos(positions * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len = x.size(1)\n",
    "        pe = self.pe[:seq_len, :]\n",
    "        pe = pe.unsqueeze(0)\n",
    "        pe = pe.expand(x.size(0), -1, -1)\n",
    "        # print(x[0], pe[0])\n",
    "        return x + pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2998f329-e1e1-4f0a-828b-7608f7650067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "class EmbeddingBlock(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, max_len, pad_id, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.token_emb = TokenEmbedding(vocab_size, embed_dim)\n",
    "        self.pos_emb = PositionalEncoder(embed_dim, max_len)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def forward(self, token_ids):\n",
    "        tok_emb = self.token_emb(token_ids) * math.sqrt(self.embed_dim)\n",
    "        print(\"te\",tok_emb)\n",
    "        x = self.pos_emb(tok_emb)\n",
    "        print(\"pe\", x)\n",
    "        return self.dropout(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "27b51e4a-760c-4f5d-ba01-80b521a07f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy = torch.tensor([[65, 0, 62, 65]])\n",
    "src_embedding_block = EmbeddingBlock(tokenizer.vocab_size, embed_dim, max_seq_len, pad_id=tokenizer.pad_token_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "84e4e33d-1224-42ce-b2af-89cc1b3b3f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "te tensor([[[-1.0169,  3.7117, -3.0031,  0.0366, -2.0964, -4.5249, -5.8190,\n",
      "           0.1423,  6.3528, -5.9342, -2.7633, -6.5703, -1.8161, -1.1127,\n",
      "          -3.3698,  1.6234],\n",
      "         [ 2.5321, -0.1290, -0.9900, -3.7510,  4.6948,  0.8859, -1.5571,\n",
      "          -2.4139, -8.1228,  1.2832, -0.7425,  1.6549, -2.8551,  2.4007,\n",
      "           5.5863,  6.4642],\n",
      "         [-1.2332, -1.0142, -4.4233,  1.6503,  0.4995,  2.1766, -4.7730,\n",
      "          -1.4999,  3.7029,  0.3568,  4.4813, -2.4508, -3.3141,  8.0293,\n",
      "          -2.5632, -2.9621],\n",
      "         [-1.0169,  3.7117, -3.0031,  0.0366, -2.0964, -4.5249, -5.8190,\n",
      "           0.1423,  6.3528, -5.9342, -2.7633, -6.5703, -1.8161, -1.1127,\n",
      "          -3.3698,  1.6234]]], grad_fn=<MulBackward0>)\n",
      "pe tensor([[[-1.0169,  4.7117, -3.0031,  1.0366, -2.0964, -3.5249, -5.8190,\n",
      "           1.1423,  6.3528, -4.9342, -2.7633, -5.5703, -1.8161, -0.1127,\n",
      "          -3.3698,  2.6234],\n",
      "         [ 3.3736,  0.4113, -0.6790, -2.8006,  4.7947,  1.8809, -1.5255,\n",
      "          -1.4144, -8.1128,  2.2831, -0.7393,  2.6549, -2.8541,  3.4007,\n",
      "           5.5866,  7.4642],\n",
      "         [-0.3239, -1.4303, -3.8322,  2.4569,  0.6982,  3.1566, -4.7098,\n",
      "          -0.5019,  3.7229,  1.3566,  4.4877, -1.4508, -3.3121,  9.0293,\n",
      "          -2.5626, -1.9621],\n",
      "         [-0.8758,  2.7217, -2.1904,  0.6194, -1.8009, -3.5696, -5.7243,\n",
      "           1.1378,  6.3828, -4.9347, -2.7538, -5.5704, -1.8131, -0.1127,\n",
      "          -3.3689,  2.6234]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "src_emb = src_embedding_block(toy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "da373a07-8a19-4c70-b8d2-fdf22ca05680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-3.8836e+00, -5.1854e+00, -6.5783e+00, -2.1027e+00, -1.6683e+00,\n",
      "           1.6579e+00,  3.7345e-01, -5.2522e+00, -3.4867e+00,  2.9524e-01,\n",
      "           1.1662e+01,  3.9204e+00,  1.1566e-01,  3.2059e+00,  9.8642e-01,\n",
      "          -6.1893e+00],\n",
      "         [ 5.9023e+00, -5.5386e-02,  3.2776e+00, -5.1518e+00,  3.4751e+00,\n",
      "           1.9231e+00,  4.2758e+00, -2.0947e+00,  1.0829e+01,  6.7652e+00,\n",
      "          -9.1369e+00, -1.0324e+01,  4.5054e+00, -5.1078e+00, -4.8536e+00,\n",
      "          -7.4253e-01],\n",
      "         [ 4.2574e+00, -1.0843e-01,  3.7641e+00, -4.0817e+00, -1.9741e+00,\n",
      "          -1.0880e-01,  6.6001e+00,  9.1309e-01, -5.4415e+00,  7.4351e-01,\n",
      "          -2.9445e+00,  1.0054e+00,  2.0926e+00,  5.4782e+00, -6.9436e+00,\n",
      "           2.9030e+00],\n",
      "         [-1.7147e+00,  4.9592e-01, -1.1170e+00,  4.5824e+00,  6.7641e+00,\n",
      "          -3.7226e+00,  1.9317e+00, -6.1815e+00, -5.9378e+00, -8.5863e-02,\n",
      "           5.1999e+00, -1.4590e+00, -2.2803e+00,  2.8240e+00,  3.1727e+00,\n",
      "           6.5920e+00],\n",
      "         [ 5.5465e-01,  1.5643e+00,  3.9880e-01,  3.0446e+00, -2.3297e+00,\n",
      "          -3.3233e+00, -1.9780e+00,  6.1356e-01, -4.5085e-01, -2.4502e+00,\n",
      "           3.0213e+00, -4.6586e+00,  3.7623e-01, -7.1361e-01,  1.0446e+00,\n",
      "          -1.7626e+00],\n",
      "         [ 3.0394e+00, -1.4477e-01,  1.2513e+00,  3.8750e+00,  1.8060e-02,\n",
      "          -1.8279e+00,  1.3996e+00,  1.6479e+00,  3.2803e+00,  4.4802e+00,\n",
      "          -6.8606e-02,  9.9332e-01,  6.3323e-01,  6.2458e+00,  4.8333e+00,\n",
      "           7.6321e-01],\n",
      "         [ 5.9023e+00, -5.5386e-02,  3.2776e+00, -5.1518e+00,  3.4751e+00,\n",
      "           1.9231e+00,  4.2758e+00, -2.0947e+00,  1.0829e+01,  6.7652e+00,\n",
      "          -9.1369e+00, -1.0324e+01,  4.5054e+00, -5.1078e+00, -4.8536e+00,\n",
      "          -7.4253e-01],\n",
      "         [ 5.7667e+00, -5.8127e+00, -1.4283e+00,  1.8133e+00, -3.9243e+00,\n",
      "           1.4286e+00, -3.7230e+00,  2.0314e+00, -3.5972e+00,  1.3210e+00,\n",
      "           3.6297e+00, -6.8355e-01, -1.6282e+00, -4.1371e+00,  2.3738e+00,\n",
      "          -1.5932e+00],\n",
      "         [ 3.0394e+00, -1.4477e-01,  1.2513e+00,  3.8750e+00,  1.8060e-02,\n",
      "          -1.8279e+00,  1.3996e+00,  1.6479e+00,  3.2803e+00,  4.4802e+00,\n",
      "          -6.8606e-02,  9.9332e-01,  6.3323e-01,  6.2458e+00,  4.8333e+00,\n",
      "           7.6321e-01],\n",
      "         [ 4.2574e+00, -1.0843e-01,  3.7641e+00, -4.0817e+00, -1.9741e+00,\n",
      "          -1.0880e-01,  6.6001e+00,  9.1309e-01, -5.4415e+00,  7.4351e-01,\n",
      "          -2.9445e+00,  1.0054e+00,  2.0926e+00,  5.4782e+00, -6.9436e+00,\n",
      "           2.9030e+00],\n",
      "         [-1.7147e+00,  4.9592e-01, -1.1170e+00,  4.5824e+00,  6.7641e+00,\n",
      "          -3.7226e+00,  1.9317e+00, -6.1815e+00, -5.9378e+00, -8.5863e-02,\n",
      "           5.1999e+00, -1.4590e+00, -2.2803e+00,  2.8240e+00,  3.1727e+00,\n",
      "           6.5920e+00],\n",
      "         [ 2.3581e+00,  1.7629e+00, -6.6384e+00,  2.9662e+00, -2.1468e+00,\n",
      "          -4.3293e+00, -8.8397e-01,  1.3794e+00, -1.5697e-02, -9.9107e-01,\n",
      "          -6.9710e-01,  5.4884e+00, -2.9343e+00,  1.6398e+00,  4.6361e+00,\n",
      "          -8.0434e+00]],\n",
      "\n",
      "        [[-3.8836e+00, -5.1854e+00, -6.5783e+00, -2.1027e+00, -1.6683e+00,\n",
      "           1.6579e+00,  3.7345e-01, -5.2522e+00, -3.4867e+00,  2.9524e-01,\n",
      "           1.1662e+01,  3.9204e+00,  1.1566e-01,  3.2059e+00,  9.8642e-01,\n",
      "          -6.1893e+00],\n",
      "         [ 5.9023e+00, -5.5386e-02,  3.2776e+00, -5.1518e+00,  3.4751e+00,\n",
      "           1.9231e+00,  4.2758e+00, -2.0947e+00,  1.0829e+01,  6.7652e+00,\n",
      "          -9.1369e+00, -1.0324e+01,  4.5054e+00, -5.1078e+00, -4.8536e+00,\n",
      "          -7.4253e-01],\n",
      "         [ 1.1173e+00, -3.2434e+00, -4.9232e+00, -1.2971e+00,  2.9131e+00,\n",
      "           9.5182e-02, -1.5032e+00, -4.1780e-01, -6.3981e+00,  1.8382e+00,\n",
      "           3.7276e+00, -4.2005e+00, -6.1009e+00, -8.5083e-01,  4.4739e-01,\n",
      "           7.7749e+00],\n",
      "         [-8.5057e-01,  8.3335e-01, -1.7384e+00, -5.6979e+00,  2.7369e+00,\n",
      "          -2.5388e+00,  6.5114e+00, -1.8644e+00, -4.5642e+00, -3.5881e-01,\n",
      "          -5.5379e-03, -1.2003e+00, -3.4813e+00, -5.6682e+00,  1.5066e+00,\n",
      "           1.0310e+00],\n",
      "         [-3.4011e+00, -6.1109e+00,  3.2238e+00, -4.2538e+00, -3.6220e-01,\n",
      "          -6.6245e+00,  1.9966e-01, -8.5480e+00, -2.0312e+00,  2.8025e+00,\n",
      "          -2.6709e+00, -6.9999e+00, -5.0551e+00,  2.5671e+00, -4.5348e+00,\n",
      "           8.5985e-01],\n",
      "         [ 3.0394e+00, -1.4477e-01,  1.2513e+00,  3.8750e+00,  1.8060e-02,\n",
      "          -1.8279e+00,  1.3996e+00,  1.6479e+00,  3.2803e+00,  4.4802e+00,\n",
      "          -6.8606e-02,  9.9332e-01,  6.3323e-01,  6.2458e+00,  4.8333e+00,\n",
      "           7.6321e-01],\n",
      "         [ 5.9023e+00, -5.5386e-02,  3.2776e+00, -5.1518e+00,  3.4751e+00,\n",
      "           1.9231e+00,  4.2758e+00, -2.0947e+00,  1.0829e+01,  6.7652e+00,\n",
      "          -9.1369e+00, -1.0324e+01,  4.5054e+00, -5.1078e+00, -4.8536e+00,\n",
      "          -7.4253e-01],\n",
      "         [ 5.9023e+00, -5.5386e-02,  3.2776e+00, -5.1518e+00,  3.4751e+00,\n",
      "           1.9231e+00,  4.2758e+00, -2.0947e+00,  1.0829e+01,  6.7652e+00,\n",
      "          -9.1369e+00, -1.0324e+01,  4.5054e+00, -5.1078e+00, -4.8536e+00,\n",
      "          -7.4253e-01],\n",
      "         [ 3.0394e+00, -1.4477e-01,  1.2513e+00,  3.8750e+00,  1.8060e-02,\n",
      "          -1.8279e+00,  1.3996e+00,  1.6479e+00,  3.2803e+00,  4.4802e+00,\n",
      "          -6.8606e-02,  9.9332e-01,  6.3323e-01,  6.2458e+00,  4.8333e+00,\n",
      "           7.6321e-01],\n",
      "         [ 5.9023e+00, -5.5386e-02,  3.2776e+00, -5.1518e+00,  3.4751e+00,\n",
      "           1.9231e+00,  4.2758e+00, -2.0947e+00,  1.0829e+01,  6.7652e+00,\n",
      "          -9.1369e+00, -1.0324e+01,  4.5054e+00, -5.1078e+00, -4.8536e+00,\n",
      "          -7.4253e-01],\n",
      "         [ 5.9475e+00,  1.8431e+00,  9.6138e-01,  5.8565e-01,  8.1224e-01,\n",
      "          -9.0960e+00,  5.3261e+00,  1.5885e+00, -8.1860e-01, -6.2506e-01,\n",
      "           6.4558e+00, -2.0893e+00,  8.6881e+00, -5.7884e+00,  4.8898e+00,\n",
      "           7.8296e-01],\n",
      "         [ 2.3581e+00,  1.7629e+00, -6.6384e+00,  2.9662e+00, -2.1468e+00,\n",
      "          -4.3293e+00, -8.8397e-01,  1.3794e+00, -1.5697e-02, -9.9107e-01,\n",
      "          -6.9710e-01,  5.4884e+00, -2.9343e+00,  1.6398e+00,  4.6361e+00,\n",
      "          -8.0434e+00]],\n",
      "\n",
      "        [[-3.8836e+00, -5.1854e+00, -6.5783e+00, -2.1027e+00, -1.6683e+00,\n",
      "           1.6579e+00,  3.7345e-01, -5.2522e+00, -3.4867e+00,  2.9524e-01,\n",
      "           1.1662e+01,  3.9204e+00,  1.1566e-01,  3.2059e+00,  9.8642e-01,\n",
      "          -6.1893e+00],\n",
      "         [ 5.9023e+00, -5.5386e-02,  3.2776e+00, -5.1518e+00,  3.4751e+00,\n",
      "           1.9231e+00,  4.2758e+00, -2.0947e+00,  1.0829e+01,  6.7652e+00,\n",
      "          -9.1369e+00, -1.0324e+01,  4.5054e+00, -5.1078e+00, -4.8536e+00,\n",
      "          -7.4253e-01],\n",
      "         [ 5.9023e+00, -5.5386e-02,  3.2776e+00, -5.1518e+00,  3.4751e+00,\n",
      "           1.9231e+00,  4.2758e+00, -2.0947e+00,  1.0829e+01,  6.7652e+00,\n",
      "          -9.1369e+00, -1.0324e+01,  4.5054e+00, -5.1078e+00, -4.8536e+00,\n",
      "          -7.4253e-01],\n",
      "         [ 1.1173e+00, -3.2434e+00, -4.9232e+00, -1.2971e+00,  2.9131e+00,\n",
      "           9.5182e-02, -1.5032e+00, -4.1780e-01, -6.3981e+00,  1.8382e+00,\n",
      "           3.7276e+00, -4.2005e+00, -6.1009e+00, -8.5083e-01,  4.4739e-01,\n",
      "           7.7749e+00],\n",
      "         [-3.4011e+00, -6.1109e+00,  3.2238e+00, -4.2538e+00, -3.6220e-01,\n",
      "          -6.6245e+00,  1.9966e-01, -8.5480e+00, -2.0312e+00,  2.8025e+00,\n",
      "          -2.6709e+00, -6.9999e+00, -5.0551e+00,  2.5671e+00, -4.5348e+00,\n",
      "           8.5985e-01],\n",
      "         [ 3.0394e+00, -1.4477e-01,  1.2513e+00,  3.8750e+00,  1.8060e-02,\n",
      "          -1.8279e+00,  1.3996e+00,  1.6479e+00,  3.2803e+00,  4.4802e+00,\n",
      "          -6.8606e-02,  9.9332e-01,  6.3323e-01,  6.2458e+00,  4.8333e+00,\n",
      "           7.6321e-01],\n",
      "         [ 5.9023e+00, -5.5386e-02,  3.2776e+00, -5.1518e+00,  3.4751e+00,\n",
      "           1.9231e+00,  4.2758e+00, -2.0947e+00,  1.0829e+01,  6.7652e+00,\n",
      "          -9.1369e+00, -1.0324e+01,  4.5054e+00, -5.1078e+00, -4.8536e+00,\n",
      "          -7.4253e-01],\n",
      "         [ 4.2574e+00, -1.0843e-01,  3.7641e+00, -4.0817e+00, -1.9741e+00,\n",
      "          -1.0880e-01,  6.6001e+00,  9.1309e-01, -5.4415e+00,  7.4351e-01,\n",
      "          -2.9445e+00,  1.0054e+00,  2.0926e+00,  5.4782e+00, -6.9436e+00,\n",
      "           2.9030e+00],\n",
      "         [ 3.0394e+00, -1.4477e-01,  1.2513e+00,  3.8750e+00,  1.8060e-02,\n",
      "          -1.8279e+00,  1.3996e+00,  1.6479e+00,  3.2803e+00,  4.4802e+00,\n",
      "          -6.8606e-02,  9.9332e-01,  6.3323e-01,  6.2458e+00,  4.8333e+00,\n",
      "           7.6321e-01],\n",
      "         [ 5.9023e+00, -5.5386e-02,  3.2776e+00, -5.1518e+00,  3.4751e+00,\n",
      "           1.9231e+00,  4.2758e+00, -2.0947e+00,  1.0829e+01,  6.7652e+00,\n",
      "          -9.1369e+00, -1.0324e+01,  4.5054e+00, -5.1078e+00, -4.8536e+00,\n",
      "          -7.4253e-01],\n",
      "         [ 3.0056e+00, -1.2499e+00, -3.1054e+00,  4.6450e+00,  1.1047e+00,\n",
      "           7.3670e-01,  3.4935e+00,  3.2050e+00, -3.5622e-01,  4.4471e+00,\n",
      "           1.2287e+00, -5.7972e+00, -3.1228e+00,  2.8259e+00, -1.1236e+00,\n",
      "           3.2679e-01],\n",
      "         [ 2.3581e+00,  1.7629e+00, -6.6384e+00,  2.9662e+00, -2.1468e+00,\n",
      "          -4.3293e+00, -8.8397e-01,  1.3794e+00, -1.5697e-02, -9.9107e-01,\n",
      "          -6.9710e-01,  5.4884e+00, -2.9343e+00,  1.6398e+00,  4.6361e+00,\n",
      "          -8.0434e+00]],\n",
      "\n",
      "        [[-3.8836e+00, -5.1854e+00, -6.5783e+00, -2.1027e+00, -1.6683e+00,\n",
      "           1.6579e+00,  3.7345e-01, -5.2522e+00, -3.4867e+00,  2.9524e-01,\n",
      "           1.1662e+01,  3.9204e+00,  1.1566e-01,  3.2059e+00,  9.8642e-01,\n",
      "          -6.1893e+00],\n",
      "         [ 5.9023e+00, -5.5386e-02,  3.2776e+00, -5.1518e+00,  3.4751e+00,\n",
      "           1.9231e+00,  4.2758e+00, -2.0947e+00,  1.0829e+01,  6.7652e+00,\n",
      "          -9.1369e+00, -1.0324e+01,  4.5054e+00, -5.1078e+00, -4.8536e+00,\n",
      "          -7.4253e-01],\n",
      "         [ 4.2574e+00, -1.0843e-01,  3.7641e+00, -4.0817e+00, -1.9741e+00,\n",
      "          -1.0880e-01,  6.6001e+00,  9.1309e-01, -5.4415e+00,  7.4351e-01,\n",
      "          -2.9445e+00,  1.0054e+00,  2.0926e+00,  5.4782e+00, -6.9436e+00,\n",
      "           2.9030e+00],\n",
      "         [ 5.5465e-01,  1.5643e+00,  3.9880e-01,  3.0446e+00, -2.3297e+00,\n",
      "          -3.3233e+00, -1.9780e+00,  6.1356e-01, -4.5085e-01, -2.4502e+00,\n",
      "           3.0213e+00, -4.6586e+00,  3.7623e-01, -7.1361e-01,  1.0446e+00,\n",
      "          -1.7626e+00],\n",
      "         [ 5.5465e-01,  1.5643e+00,  3.9880e-01,  3.0446e+00, -2.3297e+00,\n",
      "          -3.3233e+00, -1.9780e+00,  6.1356e-01, -4.5085e-01, -2.4502e+00,\n",
      "           3.0213e+00, -4.6586e+00,  3.7623e-01, -7.1361e-01,  1.0446e+00,\n",
      "          -1.7626e+00],\n",
      "         [ 3.0394e+00, -1.4477e-01,  1.2513e+00,  3.8750e+00,  1.8060e-02,\n",
      "          -1.8279e+00,  1.3996e+00,  1.6479e+00,  3.2803e+00,  4.4802e+00,\n",
      "          -6.8606e-02,  9.9332e-01,  6.3323e-01,  6.2458e+00,  4.8333e+00,\n",
      "           7.6321e-01],\n",
      "         [ 5.9023e+00, -5.5386e-02,  3.2776e+00, -5.1518e+00,  3.4751e+00,\n",
      "           1.9231e+00,  4.2758e+00, -2.0947e+00,  1.0829e+01,  6.7652e+00,\n",
      "          -9.1369e+00, -1.0324e+01,  4.5054e+00, -5.1078e+00, -4.8536e+00,\n",
      "          -7.4253e-01],\n",
      "         [ 5.9023e+00, -5.5386e-02,  3.2776e+00, -5.1518e+00,  3.4751e+00,\n",
      "           1.9231e+00,  4.2758e+00, -2.0947e+00,  1.0829e+01,  6.7652e+00,\n",
      "          -9.1369e+00, -1.0324e+01,  4.5054e+00, -5.1078e+00, -4.8536e+00,\n",
      "          -7.4253e-01],\n",
      "         [ 3.0394e+00, -1.4477e-01,  1.2513e+00,  3.8750e+00,  1.8060e-02,\n",
      "          -1.8279e+00,  1.3996e+00,  1.6479e+00,  3.2803e+00,  4.4802e+00,\n",
      "          -6.8606e-02,  9.9332e-01,  6.3323e-01,  6.2458e+00,  4.8333e+00,\n",
      "           7.6321e-01],\n",
      "         [ 5.7667e+00, -5.8127e+00, -1.4283e+00,  1.8133e+00, -3.9243e+00,\n",
      "           1.4286e+00, -3.7230e+00,  2.0314e+00, -3.5972e+00,  1.3210e+00,\n",
      "           3.6297e+00, -6.8355e-01, -1.6282e+00, -4.1371e+00,  2.3738e+00,\n",
      "          -1.5932e+00],\n",
      "         [ 5.5465e-01,  1.5643e+00,  3.9880e-01,  3.0446e+00, -2.3297e+00,\n",
      "          -3.3233e+00, -1.9780e+00,  6.1356e-01, -4.5085e-01, -2.4502e+00,\n",
      "           3.0213e+00, -4.6586e+00,  3.7623e-01, -7.1361e-01,  1.0446e+00,\n",
      "          -1.7626e+00],\n",
      "         [ 2.3581e+00,  1.7629e+00, -6.6384e+00,  2.9662e+00, -2.1468e+00,\n",
      "          -4.3293e+00, -8.8397e-01,  1.3794e+00, -1.5697e-02, -9.9107e-01,\n",
      "          -6.9710e-01,  5.4884e+00, -2.9343e+00,  1.6398e+00,  4.6361e+00,\n",
      "          -8.0434e+00]],\n",
      "\n",
      "        [[-3.8836e+00, -5.1854e+00, -6.5783e+00, -2.1027e+00, -1.6683e+00,\n",
      "           1.6579e+00,  3.7345e-01, -5.2522e+00, -3.4867e+00,  2.9524e-01,\n",
      "           1.1662e+01,  3.9204e+00,  1.1566e-01,  3.2059e+00,  9.8642e-01,\n",
      "          -6.1893e+00],\n",
      "         [ 5.9023e+00, -5.5386e-02,  3.2776e+00, -5.1518e+00,  3.4751e+00,\n",
      "           1.9231e+00,  4.2758e+00, -2.0947e+00,  1.0829e+01,  6.7652e+00,\n",
      "          -9.1369e+00, -1.0324e+01,  4.5054e+00, -5.1078e+00, -4.8536e+00,\n",
      "          -7.4253e-01],\n",
      "         [ 4.2574e+00, -1.0843e-01,  3.7641e+00, -4.0817e+00, -1.9741e+00,\n",
      "          -1.0880e-01,  6.6001e+00,  9.1309e-01, -5.4415e+00,  7.4351e-01,\n",
      "          -2.9445e+00,  1.0054e+00,  2.0926e+00,  5.4782e+00, -6.9436e+00,\n",
      "           2.9030e+00],\n",
      "         [ 1.1173e+00, -3.2434e+00, -4.9232e+00, -1.2971e+00,  2.9131e+00,\n",
      "           9.5182e-02, -1.5032e+00, -4.1780e-01, -6.3981e+00,  1.8382e+00,\n",
      "           3.7276e+00, -4.2005e+00, -6.1009e+00, -8.5083e-01,  4.4739e-01,\n",
      "           7.7749e+00],\n",
      "         [ 3.0056e+00, -1.2499e+00, -3.1054e+00,  4.6450e+00,  1.1047e+00,\n",
      "           7.3670e-01,  3.4935e+00,  3.2050e+00, -3.5622e-01,  4.4471e+00,\n",
      "           1.2287e+00, -5.7972e+00, -3.1228e+00,  2.8259e+00, -1.1236e+00,\n",
      "           3.2679e-01],\n",
      "         [ 3.0394e+00, -1.4477e-01,  1.2513e+00,  3.8750e+00,  1.8060e-02,\n",
      "          -1.8279e+00,  1.3996e+00,  1.6479e+00,  3.2803e+00,  4.4802e+00,\n",
      "          -6.8606e-02,  9.9332e-01,  6.3323e-01,  6.2458e+00,  4.8333e+00,\n",
      "           7.6321e-01],\n",
      "         [ 5.7667e+00, -5.8127e+00, -1.4283e+00,  1.8133e+00, -3.9243e+00,\n",
      "           1.4286e+00, -3.7230e+00,  2.0314e+00, -3.5972e+00,  1.3210e+00,\n",
      "           3.6297e+00, -6.8355e-01, -1.6282e+00, -4.1371e+00,  2.3738e+00,\n",
      "          -1.5932e+00],\n",
      "         [ 5.5465e-01,  1.5643e+00,  3.9880e-01,  3.0446e+00, -2.3297e+00,\n",
      "          -3.3233e+00, -1.9780e+00,  6.1356e-01, -4.5085e-01, -2.4502e+00,\n",
      "           3.0213e+00, -4.6586e+00,  3.7623e-01, -7.1361e-01,  1.0446e+00,\n",
      "          -1.7626e+00],\n",
      "         [ 3.0394e+00, -1.4477e-01,  1.2513e+00,  3.8750e+00,  1.8060e-02,\n",
      "          -1.8279e+00,  1.3996e+00,  1.6479e+00,  3.2803e+00,  4.4802e+00,\n",
      "          -6.8606e-02,  9.9332e-01,  6.3323e-01,  6.2458e+00,  4.8333e+00,\n",
      "           7.6321e-01],\n",
      "         [ 4.2574e+00, -1.0843e-01,  3.7641e+00, -4.0817e+00, -1.9741e+00,\n",
      "          -1.0880e-01,  6.6001e+00,  9.1309e-01, -5.4415e+00,  7.4351e-01,\n",
      "          -2.9445e+00,  1.0054e+00,  2.0926e+00,  5.4782e+00, -6.9436e+00,\n",
      "           2.9030e+00],\n",
      "         [-3.4011e+00, -6.1109e+00,  3.2238e+00, -4.2538e+00, -3.6220e-01,\n",
      "          -6.6245e+00,  1.9966e-01, -8.5480e+00, -2.0312e+00,  2.8025e+00,\n",
      "          -2.6709e+00, -6.9999e+00, -5.0551e+00,  2.5671e+00, -4.5348e+00,\n",
      "           8.5985e-01],\n",
      "         [ 2.3581e+00,  1.7629e+00, -6.6384e+00,  2.9662e+00, -2.1468e+00,\n",
      "          -4.3293e+00, -8.8397e-01,  1.3794e+00, -1.5697e-02, -9.9107e-01,\n",
      "          -6.9710e-01,  5.4884e+00, -2.9343e+00,  1.6398e+00,  4.6361e+00,\n",
      "          -8.0434e+00]]], grad_fn=<MulBackward0>)\n",
      "tensor([[[  6.7521,  -1.2398,   0.5054,  ...,   2.7019,   1.4952,  -1.3201],\n",
      "         [  0.3563,   0.9484,  -4.0972,  ...,   6.2245,   0.6434,  -6.7798],\n",
      "         [ -3.3323,   3.1865, -17.9011,  ...,   1.0556,   0.2709,   5.4625],\n",
      "         ...,\n",
      "         [  0.3143,   1.0625,   1.7022,  ...,  -1.7162,  -3.3544,  -2.2945],\n",
      "         [ -1.6406,  -2.5611,   3.9355,  ...,  -1.5235,  -1.7911,   2.9863],\n",
      "         [ -1.6406,  -2.5611,   3.9355,  ...,  -1.5235,  -1.7911,   2.9863]],\n",
      "\n",
      "        [[  6.7521,  -1.2398,   0.5054,  ...,   2.7019,   1.4952,  -1.3201],\n",
      "         [ -2.2408,   9.6909,   1.7943,  ...,  -4.7449,   3.0292,   0.2127],\n",
      "         [ -3.9676,   0.5965,  -2.3290,  ...,   1.6838,   0.3779,  -3.1507],\n",
      "         ...,\n",
      "         [  0.6641,   0.5043,  -1.0087,  ...,   8.2517,  -2.5522,  -3.5406],\n",
      "         [  0.3143,   1.0625,   1.7022,  ...,  -1.7162,  -3.3544,  -2.2945],\n",
      "         [ -1.6406,  -2.5611,   3.9355,  ...,  -1.5235,  -1.7911,   2.9863]],\n",
      "\n",
      "        [[  6.7521,  -1.2398,   0.5054,  ...,   2.7019,   1.4952,  -1.3201],\n",
      "         [ -8.9428,   3.1240,  -2.0669,  ...,   5.5234,  -1.8196,   3.6555],\n",
      "         [ -2.6929,  -4.0079,  -2.2916,  ...,  -3.8495,  -7.1077,  -2.9283],\n",
      "         ...,\n",
      "         [  0.6641,   0.5043,  -1.0087,  ...,   8.2517,  -2.5522,  -3.5406],\n",
      "         [  0.3143,   1.0625,   1.7022,  ...,  -1.7162,  -3.3544,  -2.2945],\n",
      "         [ -1.6406,  -2.5611,   3.9355,  ...,  -1.5235,  -1.7911,   2.9863]],\n",
      "\n",
      "        [[  6.7521,  -1.2398,   0.5054,  ...,   2.7019,   1.4952,  -1.3201],\n",
      "         [ -2.2408,   9.6909,   1.7943,  ...,  -4.7449,   3.0292,   0.2127],\n",
      "         [ -3.9676,   0.5965,  -2.3290,  ...,   1.6838,   0.3779,  -3.1507],\n",
      "         ...,\n",
      "         [  0.3143,   1.0625,   1.7022,  ...,  -1.7162,  -3.3544,  -2.2945],\n",
      "         [ -1.6406,  -2.5611,   3.9355,  ...,  -1.5235,  -1.7911,   2.9863],\n",
      "         [ -1.6406,  -2.5611,   3.9355,  ...,  -1.5235,  -1.7911,   2.9863]],\n",
      "\n",
      "        [[  6.7521,  -1.2398,   0.5054,  ...,   2.7019,   1.4952,  -1.3201],\n",
      "         [ -2.0727,   0.2487,  -1.7853,  ...,  -3.0285,  -1.6384,  -2.5806],\n",
      "         [  5.2954,  -7.1240,  -2.4397,  ...,  -3.8099,  -0.7098,  -6.1461],\n",
      "         ...,\n",
      "         [ -1.6406,  -2.5611,   3.9355,  ...,  -1.5235,  -1.7911,   2.9863],\n",
      "         [ -1.6406,  -2.5611,   3.9355,  ...,  -1.5235,  -1.7911,   2.9863],\n",
      "         [ -1.6406,  -2.5611,   3.9355,  ...,  -1.5235,  -1.7911,   2.9863]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "torch.Size([5, 12, 16]) torch.Size([5, 20, 16])\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 16\n",
    "max_seq_len = 20\n",
    "\n",
    "src_embedding_block = EmbeddingBlock(tokenizer.vocab_size, embed_dim, max_seq_len, pad_id=tokenizer.pad_token_id)\n",
    "tgt_embedding_block = EmbeddingBlock(tokenizer.vocab_size, embed_dim, max_seq_len, pad_id=tokenizer.pad_token_id)\n",
    "\n",
    "for batch_idx, (x_batch, y_batch) in enumerate(dataloader):\n",
    "    src_emb = src_embedding_block(x_batch)\n",
    "    tgt_emb = tgt_embedding_block(y_batch)\n",
    "    print(src_emb.shape, tgt_emb.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d56ebe-a939-4af5-af47-73fb0dfd171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SelfAttention(nn.Module):\n",
    "#     super.__init__(self, embed_dim):\n",
    "#     self.scale = embed_dim ** 0.5\n",
    "\n",
    "#     def forward(self, Q, K, V, mask = None):\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eacb0e9-4c86-44a5-86bb-011a65426f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class EncoderLayer(nn.Module):\n",
    "#     def __init__(self,embed_dim, num_heads, ff_hidden_dim, dropout=0.1):\n",
    "#         super.__init__()\n",
    "#         self.self_attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)\n",
    "#         self.norm1 = nn.LayerNorm(embed_dim)\n",
    "#         self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "#         self.ff = nn.Sequential(\n",
    "#             nn.Linear(embed_dim, ff_hidden_dim),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(ff_hidden_dim, embed_dim),\n",
    "#         )\n",
    "#         self.norm2 = nn.LayerNorm(embed_dim)\n",
    "#         self.dropout2 = nn.Dropout(dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d110d8ca-f796-4c86-a63f-6d51ad06f1e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
