{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed4cd61f-4659-4701-a5fe-3d4bdc4333a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "568ec2b6-6273-425d-84e2-b109ac6fb788",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "X = [[x_00, x_01, x_02],\n",
    "     [x_10, x_11, x_12],\n",
    "     [x_20, x_21, x_22]]\n",
    "\n",
    "K = [[w_00, w_01],\n",
    "     [w_10, w_11]]\n",
    "\n",
    "grad_output = a  b\n",
    "              c  d\n",
    "\n",
    "Y = y_00 y_01\n",
    "    y_10 y_11\n",
    "\n",
    "y_00 = x_00 * w_00 + x_01 * w_01 + x_10 * w_10 + x_11 * w_11\n",
    "y_01 = x_01 * w_00 + x_02 * w_01 + x_11 * w_10 + x_12 * w_11\n",
    "y_10 = x_10 * w_00 + x_11 * w_01 + x_20 * w_10 + x_21 * w_11\n",
    "y_11 = x_11 * w_00 + x_12 * w_01 + x_21 * w_10 + x_22 * w_11\n",
    "\n",
    "∂L / ∂w_00 = a * x_00 + b * x_01 + c * x_10 + d * x_11\n",
    "∂L / ∂w_01 = a * x_01 + b * x_02 + c * x_11 + d * x_12\n",
    "∂L / ∂w_10 = a * x_10 + b * x_11 + c * x_20 + d * x_21\n",
    "∂L / ∂w_11 = a * x_11 + b * x_12 + c * x_21 + d * x_22\n",
    "\n",
    "--------------------------------------------------------\n",
    "\n",
    "∂L / ∂x_00 = a * w_00\n",
    "∂L / ∂x_01 = a * w_01 + b * w_00\n",
    "∂L / ∂x_02 = b * w_01\n",
    "∂L / ∂x_10 = a * w_10 + c * w_00\n",
    "∂L / ∂x_11 = a * w_11 + b * w_10 + c * w_01 + d * w_00\n",
    "∂L / ∂x_12 = b * w_11 + d * w_01\n",
    "∂L / ∂x_20 = c * w_10\n",
    "∂L / ∂x_21 = c * w_11 + d * w_10\n",
    "∂L / ∂x_22 = d * w_11\n",
    "\n",
    "                                 \n",
    "fliplr =  w_01 w_00     flipud =  w_11 w_10\n",
    "          w_11 w_10               w_01 w_00\n",
    "\n",
    "\n",
    "grad_output_padded = 0  0  0  0\n",
    "                     0  a  b  0\n",
    "                     0  c  d  0\n",
    "                     0  0  0  0\n",
    "\n",
    "grad_input = a * w_00          a * w_01 + b * w_00                  b * w_01\n",
    "             a*w_10 + c*w_00   a*w_11 + b*w_10 + c*w_01 + d*w_00  b*w_11 + d*w_01\n",
    "             c*w_10            c*w_11 + d*w_10                       d*w_11\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class Conv2d:\n",
    "    def __init__(self, kernel_size=3):\n",
    "        self.kernel = np.random.randn(kernel_size, kernel_size) * 0.1\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.input = x\n",
    "        h, w = x.shape\n",
    "        k_h, k_w = self.kernel.shape\n",
    "        output_h = h - k_h + 1\n",
    "        output_w = w - k_w + 1\n",
    "        output = np.zeros((output_h, output_w))\n",
    "\n",
    "        for i in range(output_h):\n",
    "            for j in range(output_w):\n",
    "                region = x[i:i+k_h, j:j+k_w]\n",
    "                output[i, j] = np.sum(region * self.kernel)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        h, w = self.input.shape\n",
    "        k_h, k_w = self.kernel.shape\n",
    "        o_h, o_w = grad_output.shape\n",
    "\n",
    "        self.grad_weights = np.zeros_like(self.kernel)\n",
    "        \n",
    "        for i in range(o_h):\n",
    "            for j in range(o_w):\n",
    "                patch = self.input[i:i+k_h, j:j+k_w]\n",
    "                self.grad_weights += grad_output[i, j] * patch\n",
    "\n",
    "        flipped = np.flipud(np.fliplr(self.kernel))\n",
    "        padded_grad = np.pad(grad_output, ((k_h-1, k_h-1), (k_w-1, k_w-1)), 'constant')\n",
    "        \n",
    "        grad_input = np.zeros((h, w))\n",
    "        \n",
    "        for i in range(h):\n",
    "            for j in range(w):\n",
    "                region = padded_grad[i:i+k_h, j:j+k_w]\n",
    "                grad_input[i,j] = np.sum(region * flipped)\n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55bc3faa-9f4b-4075-93e5-203526104cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def forward(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        grad_input = grad_output.copy()\n",
    "        grad_input[self.input <= 0] = 0\n",
    "        return grad_input\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b629793-359b-452c-ba9d-1b246d0625ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dense1 -> Dense2 -> MSE\n",
    "\n",
    "For Dense1\n",
    "----\n",
    "o1 = w1 * x1 + b1\n",
    "o2 = w2 * (w1 * x1 + b1) + b2\n",
    "L = 1/2 (o2 - y) ^ 2\n",
    "\n",
    "∂L / ∂w1 = ∂L / ∂o2 * ∂o2 / ∂o1 * ∂o1 / ∂w1\n",
    "∂L / ∂o2 = o2 - y\n",
    "∂o2 / ∂o1 = w2\n",
    "∂o1 / ∂w1 = x1\n",
    "\n",
    "∂L / ∂w1 = (o2 - y) * w2 * x1\n",
    "            |          |\n",
    "        grad_output for dense 1\n",
    "∂L / ∂w2 = (o2 - y) * x2 \n",
    "           |       | \n",
    "        grad_output for dense 2\n",
    "\"\"\"\n",
    "\n",
    "class Dense:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.randn(output_size, input_size) * 0.1\n",
    "        self.biases = np.random.randn(output_size) * 0.1\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.input = x\n",
    "        return self.weights @ x + self.biases\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        self.grad_weights = np.outer(grad_output, self.input)\n",
    "        self.grad_biases = grad_output\n",
    "        \n",
    "        return self.weights.T @ grad_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93d36dff-5b98-497c-b768-fe2b6bce0c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pooling\n",
    "---\n",
    "X= 1  5  4\n",
    "   9  2  1\n",
    "   6  3  2\n",
    "\n",
    "kernel_size = 2,2\n",
    "\n",
    "Max Pooling\n",
    "--\n",
    "Y = 9 5\n",
    "    9 3\n",
    "\n",
    "|grad_output| = a b\n",
    "                c d\n",
    "\n",
    "for\n",
    "1  5\n",
    "9  2      we have a\n",
    "\n",
    "for second window b, third c, fourth d\n",
    "So,\n",
    "∂L / ∂X = 0     b  0 \n",
    "          a + c 0  0\n",
    "          0     d  0\n",
    "          \n",
    "Avg Pooling\n",
    "--\n",
    "Y = 4.25 3\n",
    "    5 2\n",
    "\n",
    "for avg we have to distribute because each value contributes equally\n",
    "\n",
    "∂L / ∂X = a/4          a/4 + b/4                b/4 \n",
    "          a/4 + c/4    a/4 + b/4 + c/4 + d/4    b/4 + d/4\n",
    "          c/4          c/4 + d/4                d/4\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Pooling:\n",
    "    def __init__(self, pool_type='max', kernel_size=(3, 3)):\n",
    "        self.pool_type = pool_type\n",
    "        self.kernel_size = kernel_size\n",
    "        self.indicies = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.input_shape = x.shape\n",
    "        h, w = x.shape\n",
    "        kh, kw = self.kernel_size\n",
    "        output_h = h - kh + 1\n",
    "        output_w = w - kw + 1\n",
    "        output = np.zeros((output_h, output_w))\n",
    "\n",
    "        self.indices = []\n",
    "\n",
    "        for i in range(output_h):\n",
    "            for j in range(output_w):\n",
    "                region = x[i:i+kh, j:j+kw]\n",
    "                if self.pool_type == 'max':\n",
    "                    output[i, j] = np.max(region)\n",
    "                    max_index = np.unravel_index(np.argmax(region), region.shape)\n",
    "                    absolute_index = (i + max_index[0], j + max_index[1])\n",
    "                    self.indices.append(absolute_index)\n",
    "                elif self.pool_type == 'avg':\n",
    "                    output[i, j] = np.mean(region)\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        grad_input = np.zeros(self.input_shape)\n",
    "        kh, kw = self.kernel_size\n",
    "        output_h, output_w = grad_output.shape\n",
    "        \n",
    "        if self.pool_type == 'max':\n",
    "            for idx, (x_i, x_j) in enumerate(self.indices):\n",
    "                i = idx // output_w\n",
    "                j = idx % output_w\n",
    "                grad_input[x_i, x_j] += grad_output[i, j]\n",
    "\n",
    "        elif self.pool_type == 'avg':\n",
    "            for i in range(output_h):\n",
    "                for j in range(output_w):\n",
    "                    grad_input[i:i+kh, j:j+kw] += grad_output[i, j] / (kh * kw)\n",
    "        return grad_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fa6d710-8d62-44f7-9439-ebc58391484a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    def forward(self, x):\n",
    "        self.input_shape = x.shape\n",
    "        return x.flatten()\n",
    "        \n",
    "    def backward(self, grad_output):\n",
    "        return grad_output.reshape(self.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa7e40fb-b01e-4126-92a2-755938e5e82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "        \n",
    "    def backward(self, grad_output):\n",
    "        for layer in reversed(self.layers):\n",
    "            grad_output = layer.backward(grad_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a7beb2a-5a80-4d72-bb5f-699c6985f19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxCrossEntropyLoss:\n",
    "    def forward(self, logits, labels):\n",
    "        self.probs = self._softmax(logits)\n",
    "        self.labels = labels\n",
    "        loss = -np.sum(labels * np.log(self.probs + 1e-9)) / logits.shape[0]\n",
    "        return loss\n",
    "\n",
    "    def backward(self):\n",
    "        return (self.probs - self.labels) / self.labels.shape[0]\n",
    "\n",
    "    def _softmax(self, x):\n",
    "        e_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return e_x / np.sum(e_x, axis=1, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "deb0e9f0-6846-475a-be55-93bdcae7a1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "\n",
    "X = mnist['data']\n",
    "y = mnist['target'].astype(np.int32)\n",
    "\n",
    "X = X / 255.0\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "X = X.reshape(-1, 28, 28)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff51b5d-dd44-477c-8c9d-31c286b54de1",
   "metadata": {},
   "source": [
    "# Tackling Around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c6e6f3fe-1be6-476f-adf2-583200e03955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 90   0   0]\n",
      " [180   0   0]]\n",
      "[[ 90   0   0]\n",
      " [180   0   0]]\n",
      "[[ 90 120 150]\n",
      " [180 210 240]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0., 10.,  0.],\n",
       "       [10., 20.,  0.],\n",
       "       [20.,  0.,  0.]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([\n",
    "    [1,2,3],\n",
    "    [4,5,6],\n",
    "    [7,8,9],\n",
    "])\n",
    "\n",
    "kernel = np.array([\n",
    "    [0, 1, 0],\n",
    "    [1, 0, 0]\n",
    "    \n",
    "])\n",
    "\n",
    "grad_output = np.array([\n",
    "    [10],\n",
    "    [20]\n",
    "])\n",
    "\n",
    "kh, kw = grad_output.shape\n",
    "out_h, out_w = grad_output.shape\n",
    "\n",
    "o1 = np.zeros_like(kernel)\n",
    "o2 = np.zeros_like(kernel)\n",
    "\n",
    "for i in range(kh):\n",
    "    for j in range(kw):\n",
    "        window = a[i:i + kh, j:j + kw]\n",
    "        # o1[i,j] = np.tensordot(window, grad_output)\n",
    "        o1[i,j] = np.sum(window * grad_output)\n",
    "\n",
    "for i in range(kh):\n",
    "    for j in range(kw):\n",
    "        for m in range(out_h):\n",
    "            for n in range(out_w):\n",
    "                o2[i, j] += a[m + i, n + j] * grad_output[m, n]\n",
    "\n",
    "o3 = np.zeros_like(kernel)\n",
    "\n",
    "H_k, W_k = kernel.shape\n",
    "H_out, W_out = grad_output.shape\n",
    "\n",
    "for i in range(H_out):\n",
    "    for j in range(W_out):\n",
    "        patch = a[i:i+H_k, j:j+W_k]\n",
    "        o3 += grad_output[i, j] * patch\n",
    "\n",
    "print(o1)\n",
    "print(o2)\n",
    "print(o3) # correct generalization\n",
    "\n",
    "\n",
    "h, w = a.shape\n",
    "kh, kw = kernel.shape\n",
    "\n",
    "\n",
    "flipped = np.flipud(np.fliplr(kernel))\n",
    "padded_grad = np.pad(grad_output, ((kh-1, kh-1), (kw-1, kw-1)), 'constant')\n",
    "\n",
    "grad_input = np.zeros((h, w))\n",
    "\n",
    "for i in range(h):\n",
    "    for j in range(w):\n",
    "        region = padded_grad[i:i+kh, j:j+kw]\n",
    "        grad_input[i,j] = np.sum(region * flipped)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "[[0 0 0 0]\n",
    " [0 1 2 0]\n",
    " [0 3 4 0]\n",
    " [0 0 0 0]]\n",
    "\n",
    " \n",
    "[[0 1]\n",
    " [1 0]]\n",
    "\"\"\"\n",
    "grad_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c182a31f-e192-48b8-a8fc-654c6caf9c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 2., 0., 0.],\n",
       "       [5., 0., 0., 9.],\n",
       "       [0., 5., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([\n",
    "    [1,5,4,8],\n",
    "    [9,2,1,12],\n",
    "    [6,3,2,9]\n",
    "])\n",
    "\n",
    "def backward(grad_output, input_shape, kernel_size, indices, pool_type):\n",
    "    grad_input = np.zeros(input_shape)\n",
    "    kh, kw = kernel_size\n",
    "    output_h, output_w = grad_output.shape\n",
    "    \n",
    "    if pool_type == 'max':\n",
    "        for idx, (x_i, x_j) in enumerate(indices):\n",
    "            i = idx // output_w\n",
    "            j = idx % output_w\n",
    "            grad_input[x_i, x_j] += grad_output[i, j]\n",
    "\n",
    "    elif pool_type == 'avg':\n",
    "        for i in range(output_h):\n",
    "            for j in range(output_w):\n",
    "                grad_input[i:i+kh, j:j+kw] += grad_output[i, j] / (kh * kw)\n",
    "\n",
    "    return grad_input\n",
    "\n",
    "b = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6]\n",
    "    \n",
    "])\n",
    "backward(b, (3,4), (2,2), [(1,0), (0,1), (1,3), (1,0), (2,1), (1,3)], \"max\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aadc063a-78fa-4eaa-aec8-b3c7c3cda6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss [0.50454905]\n",
      "Epoch 500, Loss [0.50448421]\n",
      "Epoch 1000, Loss [0.50443864]\n",
      "Epoch 1500, Loss [0.5043954]\n",
      "Epoch 2000, Loss [0.50435437]\n",
      "Epoch 2500, Loss [0.50431538]\n",
      "Epoch 3000, Loss [0.50427821]\n",
      "Epoch 3500, Loss [0.50424256]\n",
      "Epoch 4000, Loss [0.50420805]\n",
      "Epoch 4500, Loss [0.50417417]\n",
      "Epoch 5000, Loss [0.50414025]\n",
      "Epoch 5500, Loss [0.50410536]\n",
      "Epoch 6000, Loss [0.50406812]\n",
      "Epoch 6500, Loss [0.5040264]\n",
      "Epoch 7000, Loss [0.50397657]\n",
      "Epoch 7500, Loss [0.50391207]\n",
      "Epoch 8000, Loss [0.50381979]\n",
      "Epoch 8500, Loss [0.5036707]\n",
      "Epoch 9000, Loss [0.50339147]\n",
      "Epoch 9500, Loss [0.50276497]\n",
      "Epoch 10000, Loss [0.50102917]\n",
      "Epoch 10500, Loss [0.49529516]\n",
      "Epoch 11000, Loss [0.47696605]\n",
      "Epoch 11500, Loss [0.43548686]\n",
      "Epoch 12000, Loss [0.38888508]\n",
      "Epoch 12500, Loss [0.35367412]\n",
      "Epoch 13000, Loss [0.31129782]\n",
      "Epoch 13500, Loss [0.22513766]\n",
      "Epoch 14000, Loss [0.11848353]\n",
      "Epoch 14500, Loss [0.06158261]\n",
      "Epoch 15000, Loss [0.03733865]\n",
      "Epoch 15500, Loss [0.02562151]\n",
      "Epoch 16000, Loss [0.01908515]\n",
      "Epoch 16500, Loss [0.01502514]\n",
      "Epoch 17000, Loss [0.01229914]\n",
      "Epoch 17500, Loss [0.01036033]\n",
      "Epoch 18000, Loss [0.00891954]\n",
      "Epoch 18500, Loss [0.00781149]\n",
      "Epoch 19000, Loss [0.00693557]\n",
      "Epoch 19500, Loss [0.00622744]\n",
      "Epoch 20000, Loss [0.00564418]\n",
      "Epoch 20500, Loss [0.00515614]\n",
      "Epoch 21000, Loss [0.00474225]\n",
      "Epoch 21500, Loss [0.00438717]\n",
      "Epoch 22000, Loss [0.00407942]\n",
      "Epoch 22500, Loss [0.00381034]\n",
      "Epoch 23000, Loss [0.00357319]\n",
      "Epoch 23500, Loss [0.00336272]\n",
      "Epoch 24000, Loss [0.00317475]\n",
      "Epoch 24500, Loss [0.00300592]\n",
      "Epoch 25000, Loss [0.0028535]\n",
      "Epoch 25500, Loss [0.00271524]\n",
      "Epoch 26000, Loss [0.0025893]\n",
      "Epoch 26500, Loss [0.00247413]\n",
      "Epoch 27000, Loss [0.00236843]\n",
      "Epoch 27500, Loss [0.00227108]\n",
      "Epoch 28000, Loss [0.00218116]\n",
      "Epoch 28500, Loss [0.00209787]\n",
      "Epoch 29000, Loss [0.00202049]\n",
      "Epoch 29500, Loss [0.00194845]\n",
      "Epoch 30000, Loss [0.0018812]\n",
      "Epoch 30500, Loss [0.0018183]\n",
      "Epoch 31000, Loss [0.00175934]\n",
      "Epoch 31500, Loss [0.00170398]\n",
      "Epoch 32000, Loss [0.00165188]\n",
      "Epoch 32500, Loss [0.00160279]\n",
      "Epoch 33000, Loss [0.00155644]\n",
      "Epoch 33500, Loss [0.00151262]\n",
      "Epoch 34000, Loss [0.00147113]\n",
      "Epoch 34500, Loss [0.0014318]\n",
      "Epoch 35000, Loss [0.00139445]\n",
      "Epoch 35500, Loss [0.00135895]\n",
      "Epoch 36000, Loss [0.00132516]\n",
      "Epoch 36500, Loss [0.00129296]\n",
      "Epoch 37000, Loss [0.00126225]\n",
      "Epoch 37500, Loss [0.00123293]\n",
      "Epoch 38000, Loss [0.0012049]\n",
      "Epoch 38500, Loss [0.00117808]\n",
      "Epoch 39000, Loss [0.00115241]\n",
      "Epoch 39500, Loss [0.00112779]\n",
      "Epoch 40000, Loss [0.00110418]\n",
      "Epoch 40500, Loss [0.00108152]\n",
      "Epoch 41000, Loss [0.00105974]\n",
      "Epoch 41500, Loss [0.0010388]\n",
      "Epoch 42000, Loss [0.00101865]\n",
      "Epoch 42500, Loss [0.00099924]\n",
      "Epoch 43000, Loss [0.00098055]\n",
      "Epoch 43500, Loss [0.00096252]\n",
      "Epoch 44000, Loss [0.00094513]\n",
      "Epoch 44500, Loss [0.00092835]\n",
      "Epoch 45000, Loss [0.00091213]\n",
      "Epoch 45500, Loss [0.00089645]\n",
      "Epoch 46000, Loss [0.0008813]\n",
      "Epoch 46500, Loss [0.00086663]\n",
      "Epoch 47000, Loss [0.00085244]\n",
      "Epoch 47500, Loss [0.00083869]\n",
      "Epoch 48000, Loss [0.00082537]\n",
      "Epoch 48500, Loss [0.00081245]\n",
      "Epoch 49000, Loss [0.00079992]\n",
      "Epoch 49500, Loss [0.00078777]\n",
      "Input: [0 0], Predicted: 0.018, Target: 0\n",
      "Input: [0 1], Predicted: 0.981, Target: 1\n",
      "Input: [1 0], Predicted: 0.981, Target: 1\n",
      "Input: [1 1], Predicted: 0.023, Target: 0\n"
     ]
    }
   ],
   "source": [
    "           \n",
    "# XOR data\n",
    "X = np.array([\n",
    "    [0,0],\n",
    "    [0,1],\n",
    "    [1,0],\n",
    "    [1,1]\n",
    "]).T  # shape (2,4) for convenience\n",
    "\n",
    "Y = np.array([0,1,1,0])  # target outputs\n",
    "\n",
    "# Hyperparameters\n",
    "lr = 0.1\n",
    "epochs = 50000\n",
    "\n",
    "# Create model: 2 inputs -> 2 hidden units -> 1 output\n",
    "model = Model([\n",
    "    Dense(2,2),\n",
    "    Sigmoid(),\n",
    "    Dense(2,1),\n",
    "    Sigmoid()\n",
    "])\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "    for i in range(X.shape[1]):\n",
    "        x = X[:,i]\n",
    "        y = Y[i]\n",
    "        \n",
    "        # Forward\n",
    "        out = model.forward(x)\n",
    "        \n",
    "        # Compute loss (MSE)\n",
    "        loss += 0.5 * (out - y)**2\n",
    "        \n",
    "        # Backward\n",
    "        grad = out - y  # dL/dout for MSE\n",
    "        model.backward(grad)\n",
    "        \n",
    "        # Update weights\n",
    "        for layer in model.layers:\n",
    "            if isinstance(layer, Dense):\n",
    "                layer.weights -= lr * layer.grad_weights\n",
    "                layer.biases -= lr * layer.grad_biases\n",
    "                \n",
    "    if epoch % 500 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss {loss}\")\n",
    "\n",
    "# Test model\n",
    "for i in range(X.shape[1]):\n",
    "    x = X[:,i]\n",
    "    out = model.forward(x)\n",
    "    print(f\"Input: {x}, Predicted: {out[0]:.3f}, Target: {Y[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e21835f-5f99-4d21-8b4f-ff16111c6177",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
